{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b889b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "import scipy\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import butter, sosfilt, sosfreqz\n",
    "from scipy.integrate import simps\n",
    "from scipy.io.wavfile import write\n",
    "import bisect\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
    "from scipy.fftpack import dct\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "import sounddevice as sd\n",
    "import wavio as wv\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import time\n",
    "from time import sleep\n",
    "from statistics import stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b6d18",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13b23a3",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b587eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Cough Timestamps of the Data\n",
    "\n",
    "def get_real_timestamps(audio_timestamp):\n",
    "\n",
    "    timestamp = []\n",
    "    f = open(audio_timestamp, \"r\")\n",
    "    content = f.read()\n",
    "    content = content.split(\"\\n\")\n",
    "\n",
    "    for line in content:\n",
    "        if line != \"\":\n",
    "            timestamp.append(float(line.split(\"\\t\")[0]))\n",
    "    \n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f25d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all data\n",
    "def load_data(audio_file_path, timestamp_file_path, label, sr=48000):\n",
    "    \n",
    "    audio_files = [file for file in os.listdir(audio_file_path) if file.endswith('.wav')]\n",
    "    timestamp_files = [file for file in os.listdir(timestamp_file_path) if file.endswith('.txt')]\n",
    "    \n",
    "    \n",
    "    audios = []\n",
    "    timestamps = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in audio_files:\n",
    "    \n",
    "        file_name = file.split(\".wav\")[0]    \n",
    "        timestamp_files = [file[0:19] for file in timestamp_files]    \n",
    "\n",
    "        \n",
    "        # Finding correspoding timestamp file\n",
    "        index = timestamp_files.index(file_name)\n",
    "        timestamp_data = timestamp_files[index]\n",
    "\n",
    "        file_path = audio_file_path + file\n",
    "        timestamp_path = timestamp_file_path + timestamp_data + '-label.txt'\n",
    "\n",
    "        # Adding timestamps to the list\n",
    "        real_timestamps = get_real_timestamps(timestamp_path)    \n",
    "\n",
    "        # Loading audio_file\n",
    "        data, sample_rate = librosa.load(file_path, sr=sr, mono=True)\n",
    "        data = librosa.resample(data, orig_sr=sample_rate, target_sr=48000)\n",
    "        \n",
    "        audios.append(data)\n",
    "        timestamps.append(real_timestamps)\n",
    "        labels.append(label)\n",
    "\n",
    "    \n",
    "    return audios, timestamps, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3571ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = {'audio': [], 'timestamps': [], 'label': []}\n",
    "sample_rate = 48000\n",
    "\n",
    "cough_data, cough_timestamps, cough_labels = load_data('./audio-records/cough/', './audio-records/cough-timestamps/', 'cough')\n",
    "other_data, other_timestamps, other_labels = load_data('./audio-records/no-cough/', './audio-records/no-cough-timestamps/', 'other')\n",
    "\n",
    "audio_data['audio'].extend(cough_data)\n",
    "audio_data['timestamps'].extend(cough_timestamps)\n",
    "audio_data['label'].extend(cough_labels)\n",
    "\n",
    "audio_data['audio'].extend(other_data)\n",
    "audio_data['timestamps'].extend(other_timestamps)\n",
    "audio_data['label'].extend(other_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d08af",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ad0cc7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_init = pd.DataFrame.from_dict(audio_data)\n",
    "\n",
    "X_coughs = df_init[df_init['label'] == 'cough']\n",
    "y_coughs = df_init[df_init['label'] == 'cough']['label']\n",
    "\n",
    "X_others = df_init[df_init['label'] == 'other']\n",
    "y_others = df_init[df_init['label'] == 'other']['label']\n",
    "\n",
    "\n",
    "X_train_pre, X_test_init, y_train_pre, y_test_init = train_test_split(X_coughs, y_coughs, random_state= 3, train_size=0.60)\n",
    "\n",
    "X_train_init = pd.concat([X_others, X_train_pre], axis=0)\n",
    "y_train_init = pd.concat([y_others, y_train_pre], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623b1cf",
   "metadata": {},
   "source": [
    "## Data Normalization and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c172e",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e36053ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "\n",
    "def normalize_data(data):\n",
    "    min = np.min(data)\n",
    "    max = np.max(data)\n",
    "\n",
    "    data = (data - min) / (max - min)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd4d775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Average of the Data:\n",
    "def compute_moving_average(data, window_size=15):\n",
    "    \n",
    "    kernel = np.ones(window_size) / window_size\n",
    "    moving_averages = np.convolve(data, kernel, mode='valid')\n",
    "    moving_averages = np.round(moving_averages, 2)\n",
    "    \n",
    "    return np.array(moving_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ba4299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering of the data\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=8):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        sos = butter(order, [low, high], analog=False, btype='band', output='sos')\n",
    "        return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=8):\n",
    "        sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = sosfilt(sos, data)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d75b4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "def preprocess_data(data):\n",
    "    \n",
    "    # Filtering data\n",
    "    data = butter_bandpass_filter(data, 1000, 4000, sample_rate,8)\n",
    "\n",
    "    # Getting moving average of the data\n",
    "    data = compute_moving_average(np.abs(data))\n",
    "\n",
    "    # Scaling data\n",
    "    data = data.reshape(-1,1)    \n",
    "    scaler = preprocessing.StandardScaler().fit(data)\n",
    "    data = scaler.transform(data)\n",
    "    \n",
    "    # Normalize data\n",
    "    data = normalize_data(data)\n",
    "    data = data.flatten()\n",
    "    \n",
    "    return data   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1202e",
   "metadata": {},
   "source": [
    "### Percentile Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6c997d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(auc_values, threshold):\n",
    "    index = bisect.bisect_left(auc_values, threshold)\n",
    "    if index < len(auc_values):\n",
    "        return index\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f76e74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentile Points of a Signal\n",
    "\n",
    "def find_percentile_points(signal):\n",
    "    \n",
    "        # Calculating Fast Fourier Transform\n",
    "        X = np.fft.fft(signal)\n",
    "        X_mag = np.abs(X) / len(signal)\n",
    "        freqs = np.fft.fftfreq(len(signal), d=1/sample_rate)\n",
    "\n",
    "        # Graph\n",
    "        positive_freq_indices = np.where(freqs >= 0)\n",
    "\n",
    "        # Getting positive part\n",
    "        freqs = freqs[positive_freq_indices]\n",
    "        X_mag = X_mag[positive_freq_indices]\n",
    "    \n",
    "        auc = simps(X_mag, freqs)\n",
    "\n",
    "        per_25 = auc * 0.25\n",
    "        per_50 = auc * 0.50\n",
    "        per_75 = auc * 0.75\n",
    "        per_90 = auc * 0.90\n",
    "\n",
    "        # Cumulative area\n",
    "        cumulative_auc = [simps(X_mag[:i+1], freqs[:i+1]) for i in range(len(freqs))]\n",
    "\n",
    "        # Find the indices for each percentile\n",
    "        point_1 = binary_search(cumulative_auc, per_25)\n",
    "        point_2 = binary_search(cumulative_auc, per_50)\n",
    "        point_3 = binary_search(cumulative_auc, per_75)\n",
    "        point_4 = binary_search(cumulative_auc, per_90)\n",
    "\n",
    "        per_25_result = freqs[point_1]\n",
    "        per_50_result = freqs[point_2]\n",
    "        per_75_result = freqs[point_3]\n",
    "        per_90_result = freqs[point_4]\n",
    "        \n",
    "        return per_25_result, per_50_result, per_75_result, per_90_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93112b56",
   "metadata": {},
   "source": [
    "### MFCC Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "268198e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC values of a Signal\n",
    "\n",
    "def get_mfcc_features(signal):\n",
    "        \n",
    "    # Original MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate)\n",
    "    \n",
    "    # First derivative of MFCCs\n",
    "    delta_mfccs = librosa.feature.delta(mfccs)\n",
    "    \n",
    "    # Second derivative of MFCCs\n",
    "    delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "    \n",
    "    return mfccs, delta_mfccs, delta2_mfccs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916397ec",
   "metadata": {},
   "source": [
    "### Extracting Data Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41033658",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.3333333333333334, 0.3333333333333334, 0.333...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  data  label\n",
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  other\n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  other\n",
       "2    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  other\n",
       "3    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  other\n",
       "4    [0.3333333333333334, 0.3333333333333334, 0.333...  other\n",
       "..                                                 ...    ...\n",
       "331  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  cough\n",
       "332  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  cough\n",
       "333  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  cough\n",
       "334  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  cough\n",
       "335  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  cough\n",
       "\n",
       "[336 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_range_min = 0.1\n",
    "timestamp_range_max = 0.2\n",
    "data_shape = int((timestamp_range_min + timestamp_range_max) * sample_rate)\n",
    "\n",
    "extracted_train_data = {'data': [], 'label': []}\n",
    "\n",
    "\n",
    "for (info, label) in zip(X_train_init.values, y_train_init.values):\n",
    "\n",
    "    data = info[0]\n",
    "    timestamps = info[1]\n",
    "\n",
    "    data = preprocess_data(data)\n",
    "    \n",
    "    # Extracting coughs/others\n",
    "    for timestamp in timestamps:\n",
    "\n",
    "        start = int((timestamp - timestamp_range_min) * sample_rate)\n",
    "        finish = int((timestamp + timestamp_range_max) * sample_rate)\n",
    "\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "\n",
    "        if finish > len(data):\n",
    "            finish = len(data) - 1\n",
    "\n",
    "        extracted_data = data[start:finish]\n",
    "        \n",
    "        if (len(extracted_data) != data_shape):\n",
    "            continue\n",
    "            \n",
    "        extracted_train_data['data'].append(extracted_data)\n",
    "        extracted_train_data['label'].append(label)\n",
    "        \n",
    "df_train_extracted = pd.DataFrame.from_dict(extracted_train_data)\n",
    "df_train_extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b39945",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b5ed096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorednoise as cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d9422f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.00574063198332092, -0.005118991955276824, 0...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0016323857477420457, 0.003507427704693418, ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0005816653822254818, 3.373584075241028e-05,...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.046299190084906794, 0.034276161389966364, 0...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.008607918977041131, -0.007275961152912595,...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>[0.03571427408058282, 0.035714299315624434, 0....</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>[-1.1633702889923825e-08, 1.3601338721969114e-...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>[-1.1633702889923825e-08, 1.3601338721969114e-...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>[-1.1633702889923825e-08, 1.3601338721969114e-...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>[0.3076922960586048, 0.30769232129364643, 0.30...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  data  label\n",
       "0    [0.00574063198332092, -0.005118991955276824, 0...  cough\n",
       "1    [0.0016323857477420457, 0.003507427704693418, ...  other\n",
       "2    [0.0005816653822254818, 3.373584075241028e-05,...  cough\n",
       "3    [0.046299190084906794, 0.034276161389966364, 0...  other\n",
       "4    [-0.008607918977041131, -0.007275961152912595,...  cough\n",
       "..                                                 ...    ...\n",
       "331  [0.03571427408058282, 0.035714299315624434, 0....  other\n",
       "332  [-1.1633702889923825e-08, 1.3601338721969114e-...  other\n",
       "333  [-1.1633702889923825e-08, 1.3601338721969114e-...  other\n",
       "334  [-1.1633702889923825e-08, 1.3601338721969114e-...  other\n",
       "335  [0.3076922960586048, 0.30769232129364643, 0.30...  cough\n",
       "\n",
       "[336 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding white noise\n",
    "df_train_extracted = df_train_extracted.sample(frac = 1)\n",
    "\n",
    "df_train_len = len(df_train_extracted)\n",
    "div = df_train_len // 3\n",
    "\n",
    "first_quartile = df_train_extracted.iloc[:div,:]\n",
    "second_quartile = df_train_extracted.iloc[div:2*div,:]\n",
    "third_quartile = df_train_extracted.iloc[2*div:,:]\n",
    "\n",
    "augmented_data = {'data': [], 'label': []}\n",
    "\n",
    "for row in first_quartile.values:\n",
    "    \n",
    "    row_copy = row.copy()\n",
    "    data = row_copy[0]\n",
    "    label = row_copy[1]\n",
    "    \n",
    "    noise_factor = 0.005\n",
    "    white_noise = np.random.randn(len(data)) * noise_factor\n",
    "    \n",
    "    augmented_audio = data + white_noise\n",
    "    augmented_data['data'].append(augmented_audio)\n",
    "    augmented_data['label'].append(label)\n",
    "    \n",
    "for row in second_quartile.values:\n",
    "    \n",
    "    row_copy = row.copy()\n",
    "    data = row_copy[0]\n",
    "    label = row_copy[1]\n",
    "    \n",
    "    pink_noise = cn.powerlaw_psd_gaussian(1, len(data))\n",
    "\n",
    "    augmented_audio = data + pink_noise\n",
    "    augmented_data['data'].append(augmented_audio)\n",
    "    augmented_data['label'].append(label)\n",
    "    \n",
    "for row in third_quartile.values:\n",
    "    \n",
    "    row_copy = row.copy()\n",
    "    data = row_copy[0]\n",
    "    label = row_copy[1]\n",
    "    \n",
    "    background_noise, _ = librosa.load(\"./audio-records/background-noise.wav\", sr=48000)\n",
    "    background_noise = background_noise[:len(data)]\n",
    "    \n",
    "    augmented_audio = data + background_noise\n",
    "    augmented_data['data'].append(augmented_audio)\n",
    "    augmented_data['label'].append(label)\n",
    "\n",
    "    \n",
    "    \n",
    "df_augmented_data = pd.DataFrame.from_dict(augmented_data)\n",
    "df_augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a205c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_extracted = pd.concat([df_train_extracted, df_augmented_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d5a777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Audiodata_train = {'percentile_25': [], 'percentile_50': [], 'percentile_75': [], 'percentile_90': [], 'mfcc': [], 'sc':[], 'label': []}\n",
    "\n",
    "for row in df_train_extracted.values:\n",
    "\n",
    "    row_copy = row.copy()\n",
    "    extracted_data = row_copy[0]\n",
    "    label = row_copy[1]\n",
    "    \n",
    "    # Find percentile points\n",
    "    per_25, per_50, per_75, per_90 = find_percentile_points(extracted_data)\n",
    "\n",
    "    # MFCC Feature extraction\n",
    "    mfccs, delta_mfccs, delta2_mfccs = get_mfcc_features(extracted_data)\n",
    "\n",
    "    # Comprehensive MFCCs  \n",
    "    comprehensive_mfccs = np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
    "\n",
    "    # Find spectral centroids\n",
    "    sc = librosa.feature.spectral_centroid(y=extracted_data, sr=sample_rate)\n",
    "\n",
    "    Audiodata_train['percentile_25'].append(per_25)\n",
    "    Audiodata_train['percentile_50'].append(per_50)\n",
    "    Audiodata_train['percentile_75'].append(per_75)\n",
    "    Audiodata_train['percentile_90'].append(per_90)\n",
    "    Audiodata_train['mfcc'].append(comprehensive_mfccs)            \n",
    "    Audiodata_train['sc'].append(sc)\n",
    "    Audiodata_train['label'].append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfecef",
   "metadata": {},
   "source": [
    "## Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b39ca3d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data \n",
      "\n",
      "-------------------\n",
      "   percentile_25  percentile_50  percentile_75  percentile_90  \\\n",
      "0     203.333333    1150.000000    6470.000000   15096.666667   \n",
      "1    2690.000000    5953.333333   11963.333333   18823.333333   \n",
      "2     376.666667    1736.666667    6016.666667   15656.666667   \n",
      "3     180.000000     860.000000    2886.666667   10066.666667   \n",
      "4     486.666667    1953.333333    7553.333333   16173.333333   \n",
      "\n",
      "                                                mfcc  \\\n",
      "0  [[-568.9403201884962, -568.9403201884962, -457...   \n",
      "1  [[-1131.370849898476, -1131.370849898476, -113...   \n",
      "2  [[-538.4237475352473, -538.4237475352473, -538...   \n",
      "3  [[-291.41203689503476, -262.1475850721063, -24...   \n",
      "4  [[-607.3406839099096, -607.3406839099096, -607...   \n",
      "\n",
      "                                                  sc  label  \n",
      "0  [[0.0, 0.0, 4017.926870999366, 3675.5904189279...  cough  \n",
      "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  other  \n",
      "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 7054.857990262868, ...  cough  \n",
      "3  [[4921.89276374317, 4966.336668773535, 4984.76...  other  \n",
      "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5591.944452204...  cough  \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Converting the Audiodata dictionary into the pandas dataframe\n",
    "\n",
    "# Train data\n",
    "\n",
    "df_train = pd.DataFrame.from_dict(Audiodata_train)\n",
    "\n",
    "print(\"Train Data \\n\")\n",
    "print(\"-------------------\")\n",
    "print(df_train.head())\n",
    "print()\n",
    "\n",
    "mfcc_values = np.array(df_train['mfcc'].tolist())\n",
    "mfcc_values = mfcc_values.reshape(mfcc_values.shape[0], -1)\n",
    "\n",
    "sc_values = np.array(df_train['sc'].tolist())\n",
    "sc_values = sc_values.reshape(sc_values.shape[0], -1)\n",
    "\n",
    "percentile_values = df_train.iloc[:, :4].values\n",
    "\n",
    "X_train = np.concatenate((percentile_values, mfcc_values, sc_values), axis=1)\n",
    "X_train_per = percentile_values\n",
    "X_train_per_mfcc =  np.concatenate((percentile_values, mfcc_values), axis=1)\n",
    "X_train_mfcc_sc = np.concatenate((mfcc_values, sc_values), axis=1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = df_train.iloc[:, -1]\n",
    "y_train = 1 - label_encoder.fit_transform(y_train)\n",
    "\n",
    "label_counts = df_train['label'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%')\n",
    "plt.title(\"Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50260047",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a8096",
   "metadata": {},
   "source": [
    "# Extraction and Classification Performance of the Model on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17d595",
   "metadata": {},
   "source": [
    "## Time Domain Sound Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39b0a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cough Detection Algorithm\n",
    "\n",
    "def detect_coughs_time_domain(data):\n",
    "    \n",
    "    max_value = np.max(data)\n",
    "    mean_value = np.mean(data)\n",
    "    std = np.std(data)\n",
    "\n",
    "    # Threshold \n",
    "    percentile_threshold = 90\n",
    "    threshold = np.percentile(data, percentile_threshold)\n",
    "\n",
    "    # Peak detection\n",
    "    cough_indices, _ = find_peaks(data, prominence = 0.3)\n",
    "    cough_indices = list(cough_indices)\n",
    "\n",
    "    # Deleting overlaps in the peaks - Avoiding to count same cough more than one\n",
    "    i = 0\n",
    "    while i < len(cough_indices):\n",
    "\n",
    "        peak = cough_indices[i]\n",
    "        peak_range = (peak - 5000, peak + 5000) # The range is determined experimentally\n",
    "\n",
    "        overlap_indices = [index for index in cough_indices\n",
    "                       if peak_range[0] < index < peak_range[1]]\n",
    "\n",
    "        if len(overlap_indices) > 1:\n",
    "\n",
    "            # Find the index with maximum amplitude \n",
    "            max = overlap_indices[0]\n",
    "            for index in overlap_indices:\n",
    "                if (data[index] > data[max]):\n",
    "                    max = index\n",
    "\n",
    "            overlap_indices.remove(max)\n",
    "\n",
    "            for element in overlap_indices:\n",
    "                cough_indices.remove(element)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    # Applying the threshold\n",
    "    cough_indices_copy = cough_indices.copy()\n",
    "    for index in cough_indices_copy:\n",
    "\n",
    "        amplitude = data[index]\n",
    "\n",
    "        if (amplitude < threshold):\n",
    "            cough_indices.remove(index)\n",
    "\n",
    "\n",
    "    # Finding the timestamps of the coughs\n",
    "    predicted_timestamps = []\n",
    "    for index in cough_indices:\n",
    "        predicted_timestamps.append(round(index / sample_rate, 6))\n",
    "\n",
    "\n",
    "    # Filtering the sound after coughing\n",
    "    for ts in predicted_timestamps:\n",
    "        matches = list((ts_2 for ts_2 in predicted_timestamps if ts < ts_2 < ts + 0.4))\n",
    "\n",
    "        if len(matches) != 0:\n",
    "            for i in range(len(matches)):\n",
    "                index = predicted_timestamps.index(matches[i])\n",
    "                predicted_timestamps.remove(matches[i])\n",
    "                cough_indices.remove(cough_indices[index])\n",
    "\n",
    "    return cough_indices, predicted_timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b80ac0",
   "metadata": {},
   "source": [
    "## Frequency Domain Sound Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dc7b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summation of the frequency bins in a spectogram\n",
    "\n",
    "def get_frequency_sums(mel_spectrogram_db):\n",
    "    \n",
    "    sums = []\n",
    "\n",
    "    for bin in mel_spectrogram_db:\n",
    "        sums.append(np.sum(bin))\n",
    "\n",
    "    sums = np.array(sums)\n",
    "\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c39a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_coughs_freq_domain(data, percentile_threshold = 90):\n",
    "    \n",
    "    duration = len(data) / sample_rate\n",
    "    \n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=data, sr=sample_rate).T\n",
    "    mel_spectrogram_db = librosa.amplitude_to_db(mel_spectrogram, ref=np.max)    \n",
    "    \n",
    "    frequency_sums = get_frequency_sums(mel_spectrogram_db)\n",
    "    \n",
    "    # Threshold \n",
    "    threshold = np.percentile(frequency_sums, percentile_threshold)\n",
    "    \n",
    "    # Peak detection\n",
    "    cough_indices, _ = find_peaks(frequency_sums, prominence = 0.3)\n",
    "    cough_indices = list(cough_indices)\n",
    "    \n",
    "    # Deleting overlaps in the peaks - Avoiding to count same cough more than one\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(cough_indices):\n",
    "\n",
    "        peak = cough_indices[i]\n",
    "        peak_range = (peak - 50, peak + 50) # The range is determined experimentally\n",
    "\n",
    "        overlap_indices = [index for index in cough_indices\n",
    "                       if peak_range[0] < index < peak_range[1]]\n",
    "\n",
    "        if len(overlap_indices) > 1:\n",
    "\n",
    "            # Find the index with maximum amplitude \n",
    "            max = overlap_indices[0]\n",
    "            for index in overlap_indices:\n",
    "                if (frequency_sums[index] > frequency_sums[max]):\n",
    "                    max = index\n",
    "\n",
    "            overlap_indices.remove(max)\n",
    "\n",
    "            for element in overlap_indices:\n",
    "                cough_indices.remove(element)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # Applying the threshold\n",
    "    cough_indices_copy = list(cough_indices)\n",
    "    for index in cough_indices_copy: \n",
    "        amplitude = frequency_sums[index]\n",
    "        if amplitude < threshold:\n",
    "            cough_indices.remove(index)\n",
    "    \n",
    "    # Finding the timestamps of the coughs\n",
    "    predicted_timestamps = []\n",
    "    \n",
    "    total_samples = len(data)\n",
    "    data_length = len(frequency_sums)\n",
    "    \n",
    "    # Finding the timestamps of the coughs\n",
    "    for index in cough_indices:\n",
    "        \n",
    "        actual_index = total_samples * index / data_length\n",
    "        actual_timestamp = round(actual_index / sample_rate, 6)\n",
    "        \n",
    "        predicted_timestamps.append(actual_timestamp)\n",
    "    \n",
    "    # Filtering the sound after coughing\n",
    "    for ts in predicted_timestamps:\n",
    "        match = list((ts_2 for ts_2 in predicted_timestamps if ts < ts_2 < ts + 0.4))\n",
    "        if len(match) != 0:\n",
    "            index = predicted_timestamps.index(match[0])\n",
    "            predicted_timestamps.remove(match[0])\n",
    "            cough_indices.remove(cough_indices[index])\n",
    "\n",
    "    \n",
    "    return cough_indices, predicted_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7fa07f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_coughs(preprocessed_data, model, extracted_test_data):\n",
    "\n",
    "    # Extraction of high frequency signals (cough/other) from the audio\n",
    "    audio_peak_extractions = []\n",
    "    \n",
    "    # Time-based and frequency-based extractions\n",
    "    cough_indices_time, predicted_timestamps_time = detect_coughs_time_domain(preprocessed_data)\n",
    "    cough_indices_freq, predicted_timestamps_freq = detect_coughs_freq_domain(preprocessed_data)\n",
    "\n",
    "    predicted_timestamps = []\n",
    "\n",
    "    # Getting predicted timestamps by comparing time-based and frequency-based extractions\n",
    "\n",
    "    for timestamp in predicted_timestamps_freq:\n",
    "\n",
    "        if any(timestamp - 0.15 < element < timestamp + 0.15 for element in predicted_timestamps_time):\n",
    "\n",
    "            predicted_timestamps.append(timestamp)\n",
    "        \n",
    "    # Getting the extracted data\n",
    "    for timestamp in predicted_timestamps:\n",
    "\n",
    "        start = int((timestamp - timestamp_range_min) * sample_rate)\n",
    "        finish = int((timestamp + timestamp_range_max) * sample_rate)\n",
    "\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "\n",
    "        if finish > len(preprocessed_data):\n",
    "            finish = len(preprocessed_data) - 1\n",
    "\n",
    "        extracted_data = preprocessed_data[start:finish]\n",
    "    \n",
    "        # Add padding or truncate if necessary\n",
    "        if len(extracted_data) < data_shape:\n",
    "            \n",
    "            padding_size = data_shape - len(extracted_data)\n",
    "            left_padding = padding_size // 2\n",
    "            right_padding = padding_size - left_padding\n",
    "\n",
    "            extracted_data = np.pad(extracted_data, (left_padding, right_padding), mode='constant', constant_values=0)\n",
    "\n",
    "        elif len(extracted_data) > data_shape:\n",
    "            extracted_data = extracted_data[:data_shape]\n",
    "\n",
    "        audio_peak_extractions.append((extracted_data, timestamp))\n",
    "        extracted_test_data['data'].append(extracted_data)\n",
    "    \n",
    "    # Getting features of the extracted audio data\n",
    "    Audiodata_new = {'percentile_25': [], 'percentile_50': [], 'percentile_75': [], 'percentile_90': [], 'mfcc': [], 'sc':[]}\n",
    "    \n",
    "    for peak, timestamp in audio_peak_extractions:\n",
    "\n",
    "        # Percentile Calculation\n",
    "        per_25, per_50, per_75, per_90 = find_percentile_points(peak)\n",
    "\n",
    "\n",
    "        # MFCC Feature extraction\n",
    "        mfccs, delta_mfccs, delta2_mfccs = get_mfcc_features(peak)\n",
    "\n",
    "        # Comprehensive MFCCs\n",
    "        comprehensive_mfccs = np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
    "\n",
    "        # Find spectral centroids\n",
    "        sc = librosa.feature.spectral_centroid(y=peak, sr=sample_rate)\n",
    "\n",
    "        Audiodata_new['percentile_25'].append(per_25)\n",
    "        Audiodata_new['percentile_50'].append(per_50)\n",
    "        Audiodata_new['percentile_75'].append(per_75)\n",
    "        Audiodata_new['percentile_90'].append(per_90)\n",
    "        Audiodata_new['mfcc'].append(comprehensive_mfccs)\n",
    "        Audiodata_new['sc'].append(sc)\n",
    "\n",
    "\n",
    "    df_new = pd.DataFrame.from_dict(Audiodata_new)\n",
    "    \n",
    "    try:\n",
    "    # Both MFCCs and Percentiles\n",
    "        mfcc_values = np.array(df_new['mfcc'].tolist())\n",
    "        mfcc_values = mfcc_values.reshape(mfcc_values.shape[0], -1)\n",
    "\n",
    "        sc_values = np.array(df_new['sc'].tolist())\n",
    "        sc_values = sc_values.reshape(sc_values.shape[0], -1)\n",
    "\n",
    "        percentile_values = df_new.iloc[:, :4].values\n",
    "\n",
    "        new_data = np.concatenate((percentile_values, mfcc_values, sc_values), axis=1)    \n",
    "        prediction = model.predict(new_data)\n",
    "\n",
    "        final_prediction = []\n",
    "\n",
    "        for i in range(len(predicted_timestamps)):\n",
    "            if (prediction[i] == 1):\n",
    "                final_prediction.append(predicted_timestamps[i])\n",
    "\n",
    "        #print(f\"P Timestamps: {predicted_timestamps}\")\n",
    "        return final_prediction\n",
    "    \n",
    "    except: \n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4840bad",
   "metadata": {},
   "source": [
    "# Prediction and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "319f75b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[-0.0014953613, -0.0015258789, -0.0014953613, ...</td>\n",
       "      <td>[1.973696, 4.708879, 14.192288, 27.790743]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.05895996, 0.06600952, 0.06201172, 0.0666198...</td>\n",
       "      <td>[4.8878, 23.045805, 44.501043, 45.83619, 47.41...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.865809, 2.365563, 13.204682, 13.671662, 22....</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.012420654, 0.025421143, 0.030853271, 0.0290...</td>\n",
       "      <td>[2.233332, 3.304087, 11.01195, 23.563642]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.793256, 4.184563, 9.78828, 10.954947, 17.44...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.100679, 3.424441, 5.165727]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-0.0004272461, -0.00048828125, -0.00061035156...</td>\n",
       "      <td>[4.007188, 6.963311, 12.021565, 23.231565, 27....</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.006500244, 0.0027160645, -0.0010986328, -0....</td>\n",
       "      <td>[3.297234, 11.052698, 18.761723]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[-0.003540039, -0.0073242188, -0.008422852, -0...</td>\n",
       "      <td>[39.404319]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.001159668, 0.002380371, 0.0030212402, 0.003...</td>\n",
       "      <td>[1.116596, 44.99989]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.950024, 4.308214, 5.214044, 5.867127]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[-0.0009460449, -0.00048828125, -0.0008239746,...</td>\n",
       "      <td>[1.016298, 12.466887, 28.873712, 42.096383]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-0.0014038086, -0.0014648438, -0.0015563965, ...</td>\n",
       "      <td>[1.790415, 11.721125, 22.099867]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.903657, 1.288308, 1.673156, 3.463981, 3.922...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[-0.0016174316, -0.0034179688, -0.004119873, -...</td>\n",
       "      <td>[2.596367, 34.022857, 36.645362, 41.720474]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[-0.00030517578, -0.00091552734, -0.0010375977...</td>\n",
       "      <td>[29.998833, 39.777377]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.671385, 2.249385, 2.779219, 4.31092, 4.8648...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.033416748, 0.044677734, 0.048095703, 0.0523...</td>\n",
       "      <td>[2.530975, 11.993107, 39.288163, 51.734059]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                audio  \\\n",
       "12  [-0.0014953613, -0.0015258789, -0.0014953613, ...   \n",
       "44  [0.05895996, 0.06600952, 0.06201172, 0.0666198...   \n",
       "23  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9   [0.012420654, 0.025421143, 0.030853271, 0.0290...   \n",
       "13  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "16  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6   [-0.0004272461, -0.00048828125, -0.00061035156...   \n",
       "4   [0.006500244, 0.0027160645, -0.0010986328, -0....   \n",
       "33  [-0.003540039, -0.0073242188, -0.008422852, -0...   \n",
       "40  [0.001159668, 0.002380371, 0.0030212402, 0.003...   \n",
       "27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "18  [-0.0009460449, -0.00048828125, -0.0008239746,...   \n",
       "15  [-0.0014038086, -0.0014648438, -0.0015563965, ...   \n",
       "31  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "11  [-0.0016174316, -0.0034179688, -0.004119873, -...   \n",
       "35  [-0.00030517578, -0.00091552734, -0.0010375977...   \n",
       "36  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "25  [0.033416748, 0.044677734, 0.048095703, 0.0523...   \n",
       "\n",
       "                                           timestamps  label  \n",
       "12         [1.973696, 4.708879, 14.192288, 27.790743]  cough  \n",
       "44  [4.8878, 23.045805, 44.501043, 45.83619, 47.41...  cough  \n",
       "23  [1.865809, 2.365563, 13.204682, 13.671662, 22....  cough  \n",
       "9           [2.233332, 3.304087, 11.01195, 23.563642]  cough  \n",
       "13  [3.793256, 4.184563, 9.78828, 10.954947, 17.44...  cough  \n",
       "16                     [1.100679, 3.424441, 5.165727]  cough  \n",
       "6   [4.007188, 6.963311, 12.021565, 23.231565, 27....  cough  \n",
       "4                    [3.297234, 11.052698, 18.761723]  cough  \n",
       "33                                        [39.404319]  cough  \n",
       "40                               [1.116596, 44.99989]  cough  \n",
       "27           [3.950024, 4.308214, 5.214044, 5.867127]  cough  \n",
       "18        [1.016298, 12.466887, 28.873712, 42.096383]  cough  \n",
       "15                   [1.790415, 11.721125, 22.099867]  cough  \n",
       "31  [0.903657, 1.288308, 1.673156, 3.463981, 3.922...  cough  \n",
       "11        [2.596367, 34.022857, 36.645362, 41.720474]  cough  \n",
       "35                             [29.998833, 39.777377]  cough  \n",
       "36  [1.671385, 2.249385, 2.779219, 4.31092, 4.8648...  cough  \n",
       "25        [2.530975, 11.993107, 39.288163, 51.734059]  cough  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data loading\n",
    "\n",
    "audio_data_test = X_test_init.copy()\n",
    "\n",
    "audio_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "945e86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(models_list, model_hyperparameters):\n",
    "    \n",
    "    results = []\n",
    "    model_keys = list(model_hyperparameters.keys())\n",
    "    \n",
    "    for i in range(len(models_list)):\n",
    "        \n",
    "        key = model_keys[i]\n",
    "        params = model_hyperparameters[key]\n",
    "        \n",
    "        classifier = GridSearchCV(models_list[i], params, cv=5, scoring='f1')\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        results.append({\n",
    "            'model used': models_list[i],\n",
    "            'highest score': classifier.best_score_,\n",
    "            'best hyperparameters': classifier.best_params_,\n",
    "            \n",
    "        })\n",
    "\n",
    "    \n",
    "    result_dataframe = pd.DataFrame(results, columns = ['model used', 'highest score', 'best hyperparameters'])    \n",
    "    return result_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d1427a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Models: \n",
    "\n",
    "0                                           SVC(C=0.5)\n",
    "1    KNeighborsClassifier(n_neighbors=161, weights=...\n",
    "2    (DecisionTreeClassifier(max_features='sqrt', r...\n",
    "3      GaussianNB(var_smoothing=5.336699231206313e-07)\n",
    "\n",
    "\"\"\"\n",
    "models_list = [SVC(), KNeighborsClassifier(), RandomForestClassifier(random_state=0), GaussianNB()]\n",
    "\n",
    "\n",
    "model_hyperparameters = {\n",
    "\n",
    "    'svc_hyperparameters': {\n",
    "        \n",
    "        'C': [0.5, 1, 10, 100],\n",
    "        'gamma': ['scale', 1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'kernel': ['rbf']\n",
    "        \n",
    "    },\n",
    "    \n",
    "    'KNN_hyperparameters': {\n",
    "        \n",
    "        'n_neighbors': list(range(3, int(len(X_train) * 0.65),2)),\n",
    "        'weights': ['uniform', 'distance']\n",
    "\n",
    "    },\n",
    "    \n",
    "    'random_forest_hyperparameters': {\n",
    "        \n",
    "        'n_estimators': [10, 20, 50, 100]\n",
    "    },\n",
    "    \n",
    "    'naive_bayes_hyperparameters': {\n",
    "    \n",
    "        'var_smoothing': np.logspace(0,-9, num=100)\n",
    "    },\n",
    "        \n",
    "}\n",
    "\n",
    "result_df = model_selection(models_list, model_hyperparameters)\n",
    "\n",
    "for model_info in result_df.values:\n",
    "    \n",
    "    model = model_info[0]\n",
    "    best_params = model_info[2]\n",
    "    \n",
    "    model.set_params(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "model_list = result_df['model used']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3d36ae28",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "detect_coughs() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m data \u001b[38;5;241m=\u001b[39m preprocess_data(data)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#print(f\"R Timestamps: {timestamps}\")\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m detected_cough_timestamps \u001b[38;5;241m=\u001b[39m detect_coughs(data, model, extracted_test_data)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#print()\u001b[39;00m\n\u001b[1;32m     15\u001b[0m predicted_and_real_timestamps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(timestamps)\n",
      "\u001b[0;31mTypeError\u001b[0m: detect_coughs() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "predicted_and_real_timestamps = {'real': [], 'predicted': []}\n",
    "extracted_test_data = {'data': [], 'label': []}\n",
    "\n",
    "for row in audio_data_test.values:\n",
    "\n",
    "    data = row[0]\n",
    "    timestamps = row[1]\n",
    "\n",
    "    data = preprocess_data(data)\n",
    "\n",
    "    #print(f\"R Timestamps: {timestamps}\")\n",
    "    detected_cough_timestamps = detect_coughs(data, model, extracted_test_data)\n",
    "    #print()\n",
    "\n",
    "    predicted_and_real_timestamps['real'].append(timestamps)\n",
    "    predicted_and_real_timestamps['predicted'].append(detected_cough_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aacd4d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
      "-----------------------------\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(fn)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(fp)\n\u001b[0;32m---> 39\u001b[0m recall \u001b[38;5;241m=\u001b[39m tp \u001b[38;5;241m/\u001b[39m (tp \u001b[38;5;241m+\u001b[39m fn)\n\u001b[1;32m     40\u001b[0m precision \u001b[38;5;241m=\u001b[39m tp \u001b[38;5;241m/\u001b[39m (tp \u001b[38;5;241m+\u001b[39m fp)\n\u001b[1;32m     41\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m recall \u001b[38;5;241m*\u001b[39m precision \u001b[38;5;241m/\u001b[39m (recall \u001b[38;5;241m+\u001b[39m precision)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# KNN Prediction\n",
    "\n",
    "model = models_list[1]\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "print(model)\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "\n",
    "    \n",
    "pr_df = pd.DataFrame.from_dict(predicted_and_real_timestamps)\n",
    "\n",
    "for row in pr_df.values:\n",
    "\n",
    "    real_timestamps = row[0]\n",
    "    predicted_timestamps = row[1]\n",
    "\n",
    "    real_timestamps.sort()\n",
    "    predicted_timestamps.sort()\n",
    "\n",
    "    #plt.figure(figsize=(6, 3))\n",
    "\n",
    "    for real, pred in zip(real_timestamps, predicted_timestamps):\n",
    "        if any(real - 0.15 < p < real + 0.15 for p in predicted_timestamps):\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "        if not any(pred - 0.15 < r < pred + 0.15 for r in real_timestamps):\n",
    "            fp += 1\n",
    "\n",
    "print(tp)\n",
    "print(fn)\n",
    "print(fp)\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "f1 = 2 * recall * precision / (recall + precision)\n",
    "\n",
    "print(f\"The F1 score of {model}: {round(f1,3)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7437408",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100)\n",
      "-----------------------------\n",
      "The F1 score of SVC(C=100): 0.75\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
      "-----------------------------\n",
      "The F1 score of KNeighborsClassifier(n_neighbors=3, weights='distance'): 0.723\n",
      "\n",
      "RandomForestClassifier(random_state=0)\n",
      "-----------------------------\n",
      "The F1 score of RandomForestClassifier(random_state=0): 0.743\n",
      "\n",
      "GaussianNB(var_smoothing=8.111308307896856e-09)\n",
      "-----------------------------\n",
      "The F1 score of GaussianNB(var_smoothing=8.111308307896856e-09): 0.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in model_list: \n",
    "        \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    print(model)\n",
    "    print(\"-----------------------------\")\n",
    "    \n",
    "    predicted_and_real_timestamps = {'real': [], 'predicted': []}\n",
    "\n",
    "    for row in audio_data_test.values:\n",
    "\n",
    "        data = row[0]\n",
    "        timestamps = row[1]\n",
    "\n",
    "        data = preprocess_data(data)\n",
    "\n",
    "        #print(f\"R Timestamps: {timestamps}\")\n",
    "        detected_cough_timestamps = detect_coughs(data, model)\n",
    "        #print()\n",
    "\n",
    "        predicted_and_real_timestamps['real'].append(timestamps)\n",
    "        predicted_and_real_timestamps['predicted'].append(detected_cough_timestamps)\n",
    "\n",
    "    \"\"\"2\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Real\")\n",
    "    plt.plot(time, data, label='Signal')\n",
    "    plt.scatter(timestamps, np.zeros_like(timestamps), marker='o', color='red', label='Real Timestamps', s=10, zorder=5)\n",
    "\n",
    "    # Plot predicted timestamps\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.plot(time, data, label='Signal')\n",
    "    plt.scatter(detected_cough_timestamps, np.zeros_like(detected_cough_timestamps), marker='o', color='red', label='Predicted Timestamps', s=10, zorder=5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print()\n",
    "    \"\"\"\n",
    "\n",
    "    pr_df = pd.DataFrame.from_dict(predicted_and_real_timestamps)\n",
    "\n",
    "    for row in pr_df.values:\n",
    "\n",
    "        real_timestamps = row[0]\n",
    "        predicted_timestamps = row[1]\n",
    "\n",
    "        real_timestamps.sort()\n",
    "        predicted_timestamps.sort()\n",
    "        \n",
    "        #plt.figure(figsize=(6, 3))\n",
    "\n",
    "        for real, pred in zip(real_timestamps, predicted_timestamps):\n",
    "            if any(real - 0.15 < p < real + 0.15 for p in predicted_timestamps):\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "\n",
    "            if not any(pred - 0.15 < r < pred + 0.15 for r in real_timestamps):\n",
    "                fp += 1\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    f1 = 2 * recall * precision / (recall + precision)\n",
    "\n",
    "    print(f\"The F1 score of {model}: {round(f1,3)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8041bf",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "99fb4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c5f5607d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_melspectrogram(data):\n",
    "    \n",
    "    melspec = librosa.feature.melspectrogram(y = data,\n",
    "                                                  sr = sample_rate, \n",
    "                                                  n_fft = 512, \n",
    "                                                  hop_length = 256, \n",
    "                                                  n_mels = 40).T\n",
    "\n",
    "    melspec = librosa.power_to_db(melspec)\n",
    "    \n",
    "    return melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "508bb295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>[0.04166666666666667, 0.04166666666666667, 0.0...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>[0.03571427408058282, 0.035714299315624434, 0....</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>[-1.1633702889923825e-08, 1.3601338721969114e-...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>[-1.1633702889923825e-08, 1.3601338721969114e-...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>[-1.1633702889923825e-08, 1.3601338721969114e-...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>[0.3076922960586048, 0.30769232129364643, 0.30...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  data  label\n",
       "276  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  cough\n",
       "88   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  other\n",
       "289  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  cough\n",
       "120  [0.04166666666666667, 0.04166666666666667, 0.0...  other\n",
       "269  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  cough\n",
       "..                                                 ...    ...\n",
       "331  [0.03571427408058282, 0.035714299315624434, 0....  other\n",
       "332  [-1.1633702889923825e-08, 1.3601338721969114e-...  other\n",
       "333  [-1.1633702889923825e-08, 1.3601338721969114e-...  other\n",
       "334  [-1.1633702889923825e-08, 1.3601338721969114e-...  other\n",
       "335  [0.3076922960586048, 0.30769232129364643, 0.30...  cough\n",
       "\n",
       "[672 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0d900941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2):\n",
    "        \n",
    "    n_mels, n_steps = spec.shape\n",
    "    mask_value = spec.mean()\n",
    "    aug_spec = spec\n",
    "\n",
    "    freq_mask_param = max_mask_pct * n_mels\n",
    "    for _ in range(n_freq_masks):\n",
    "      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    time_mask_param = max_mask_pct * n_steps\n",
    "    for _ in range(n_time_masks):\n",
    "      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    return aug_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b401c447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melspectrograms\n",
    "mel_dict = {'data': [], 'label': []}\n",
    "\n",
    "for row in df_train_extracted.values:\n",
    "    \n",
    "    data = row[0]\n",
    "    label = row[1]\n",
    "    \n",
    "    melspec = get_melspectrogram(data)\n",
    "    melspec = torch.tensor(melspec)\n",
    "\n",
    "    mel_dict['data'].append(melspec)\n",
    "    mel_dict['label'].append(label)   \n",
    "    \n",
    "    augmented_spec = spectro_augment(spec)  \n",
    "    mel_dict['data'].append(augmented_spec)\n",
    "    mel_dict['label'].append(label)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "22ef0984",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpecDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        spec = self.dataframe.loc[idx, 'data']\n",
    "        label = self.dataframe.loc[idx, 'label']\n",
    "        return spec, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9c098b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mel_spec = pd.DataFrame.from_dict(mel_dict)\n",
    "train_ds = MelSpecDataset(df_mel_spec)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abbb304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

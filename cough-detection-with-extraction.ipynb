{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1b889b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "import scipy\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import butter, sosfilt, sosfreqz\n",
    "from scipy.integrate import simps\n",
    "from scipy.io.wavfile import write\n",
    "import bisect\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
    "from scipy.fftpack import dct\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "import sounddevice as sd\n",
    "import wavio as wv\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import time\n",
    "from time import sleep\n",
    "from statistics import stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b6d18",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13b23a3",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b587eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Cough Timestamps of the Data\n",
    "\n",
    "def get_real_timestamps(audio_timestamp):\n",
    "\n",
    "    timestamp = []\n",
    "    f = open(audio_timestamp, \"r\")\n",
    "    content = f.read()\n",
    "    content = content.split(\"\\n\")\n",
    "\n",
    "    for line in content:\n",
    "        if line != \"\":\n",
    "            timestamp.append(float(line.split(\"\\t\")[0]))\n",
    "    \n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "63f25d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all data\n",
    "def load_data(audio_file_path, timestamp_file_path, label, sr=48000):\n",
    "    \n",
    "    audio_files = [file for file in os.listdir(audio_file_path) if file.endswith('.wav')]\n",
    "    timestamp_files = [file for file in os.listdir(timestamp_file_path) if file.endswith('.txt')]\n",
    "    \n",
    "    \n",
    "    audios = []\n",
    "    timestamps = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in audio_files:\n",
    "    \n",
    "        file_name = file.split(\".wav\")[0]    \n",
    "        timestamp_files = [file[0:19] for file in timestamp_files]    \n",
    "\n",
    "        \n",
    "        # Finding correspoding timestamp file\n",
    "        index = timestamp_files.index(file_name)\n",
    "        timestamp_data = timestamp_files[index]\n",
    "\n",
    "        file_path = audio_file_path + file\n",
    "        timestamp_path = timestamp_file_path + timestamp_data + '-label.txt'\n",
    "\n",
    "        # Adding timestamps to the list\n",
    "        real_timestamps = get_real_timestamps(timestamp_path)    \n",
    "\n",
    "        # Loading audio_file\n",
    "        data, sample_rate = librosa.load(file_path, sr=sr, mono=True)\n",
    "        data = librosa.resample(data, orig_sr=sample_rate, target_sr=48000)\n",
    "        \n",
    "        audios.append(data)\n",
    "        timestamps.append(real_timestamps)\n",
    "        labels.append(label)\n",
    "\n",
    "    \n",
    "    return audios, timestamps, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3571ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = {'audio': [], 'timestamps': [], 'label': []}\n",
    "sample_rate = 48000\n",
    "\n",
    "cough_data, cough_timestamps, cough_labels = load_data('./audio-records/cough/', './audio-records/cough-timestamps/', 'cough')\n",
    "other_data, other_timestamps, other_labels = load_data('./audio-records/no-cough/', './audio-records/no-cough-timestamps/', 'other')\n",
    "\n",
    "audio_data['audio'].extend(cough_data)\n",
    "audio_data['timestamps'].extend(cough_timestamps)\n",
    "audio_data['label'].extend(cough_labels)\n",
    "\n",
    "audio_data['audio'].extend(other_data)\n",
    "audio_data['timestamps'].extend(other_timestamps)\n",
    "audio_data['label'].extend(other_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d08af",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1ad0cc7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44    other\n",
      "45    other\n",
      "46    other\n",
      "47    other\n",
      "48    other\n",
      "      ...  \n",
      "0     cough\n",
      "8     cough\n",
      "3     cough\n",
      "24    cough\n",
      "42    cough\n",
      "Name: label, Length: 73, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_init = pd.DataFrame.from_dict(audio_data)\n",
    "\n",
    "X_coughs = df_init[df_init['label'] == 'cough']\n",
    "y_coughs = df_init[df_init['label'] == 'cough']['label']\n",
    "\n",
    "X_others = df_init[df_init['label'] == 'other']\n",
    "y_others = df_init[df_init['label'] == 'other']['label']\n",
    "\n",
    "\n",
    "X_train_pre, X_test_init, y_train_pre, y_test_init = train_test_split(X_coughs, y_coughs, random_state= 3, train_size=0.80)\n",
    "\n",
    "X_train_init = pd.concat([X_others, X_train_pre], axis=0)\n",
    "y_train_init = pd.concat([y_others, y_train_pre], axis=0)\n",
    "\n",
    "print(y_train_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623b1cf",
   "metadata": {},
   "source": [
    "## Data Normalization and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c172e",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e36053ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "\n",
    "def normalize_data(data):\n",
    "    min = np.min(data)\n",
    "    max = np.max(data)\n",
    "\n",
    "    data = (data - min) / (max - min)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bd4d775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Average of the Data:\n",
    "def compute_moving_average(data, window_size=15):\n",
    "    \n",
    "    kernel = np.ones(window_size) / window_size\n",
    "    moving_averages = np.convolve(data, kernel, mode='valid')\n",
    "    moving_averages = np.round(moving_averages, 2)\n",
    "    \n",
    "    return np.array(moving_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "88ba4299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering of the data\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=8):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        sos = butter(order, [low, high], analog=False, btype='band', output='sos')\n",
    "        return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=8):\n",
    "        sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = sosfilt(sos, data)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d75b4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "def preprocess_data(data):\n",
    "    \n",
    "    # Filtering data\n",
    "    data = butter_bandpass_filter(data, 1000, 4000, sample_rate,8)\n",
    "\n",
    "    # Getting moving average of the data\n",
    "    data = compute_moving_average(np.abs(data))\n",
    "\n",
    "    # Scaling data\n",
    "    data = data.reshape(-1,1)    \n",
    "    scaler = preprocessing.StandardScaler().fit(data)\n",
    "    data = scaler.transform(data)\n",
    "    \n",
    "    # Normalize data\n",
    "    data = normalize_data(data)\n",
    "    data = data.flatten()\n",
    "    \n",
    "    return data   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1202e",
   "metadata": {},
   "source": [
    "### Percentile Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e6c997d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(auc_values, threshold):\n",
    "    index = bisect.bisect_left(auc_values, threshold)\n",
    "    if index < len(auc_values):\n",
    "        return index\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f76e74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentile Points of a Signal\n",
    "\n",
    "def find_percentile_points(signal):\n",
    "    \n",
    "        # Calculating Fast Fourier Transform\n",
    "        X = np.fft.fft(signal)\n",
    "        X_mag = np.abs(X) / len(signal)\n",
    "        freqs = np.fft.fftfreq(len(signal), d=1/sample_rate)\n",
    "\n",
    "        # Graph\n",
    "        positive_freq_indices = np.where(freqs >= 0)\n",
    "\n",
    "        # Getting positive part\n",
    "        freqs = freqs[positive_freq_indices]\n",
    "        X_mag = X_mag[positive_freq_indices]\n",
    "    \n",
    "        auc = simps(X_mag, freqs)\n",
    "\n",
    "        per_25 = auc * 0.25\n",
    "        per_50 = auc * 0.50\n",
    "        per_75 = auc * 0.75\n",
    "        per_90 = auc * 0.90\n",
    "\n",
    "        # Cumulative area\n",
    "        cumulative_auc = [simps(X_mag[:i+1], freqs[:i+1]) for i in range(len(freqs))]\n",
    "\n",
    "        # Find the indices for each percentile\n",
    "        point_1 = binary_search(cumulative_auc, per_25)\n",
    "        point_2 = binary_search(cumulative_auc, per_50)\n",
    "        point_3 = binary_search(cumulative_auc, per_75)\n",
    "        point_4 = binary_search(cumulative_auc, per_90)\n",
    "\n",
    "        per_25_result = freqs[point_1]\n",
    "        per_50_result = freqs[point_2]\n",
    "        per_75_result = freqs[point_3]\n",
    "        per_90_result = freqs[point_4]\n",
    "        \n",
    "        return per_25_result, per_50_result, per_75_result, per_90_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93112b56",
   "metadata": {},
   "source": [
    "### MFCC Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "268198e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC values of a Signal\n",
    "\n",
    "def get_mfcc_features(signal):\n",
    "        \n",
    "    # Original MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate)\n",
    "    \n",
    "    # First derivative of MFCCs\n",
    "    delta_mfccs = librosa.feature.delta(mfccs)\n",
    "    \n",
    "    # Second derivative of MFCCs\n",
    "    delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "    \n",
    "    return mfccs, delta_mfccs, delta2_mfccs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916397ec",
   "metadata": {},
   "source": [
    "### Extracting Data Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "41033658",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "timestamp_range_min = 0.1\n",
    "timestamp_range_max = 0.2\n",
    "data_shape = int((timestamp_range_min + timestamp_range_max) * sample_rate)\n",
    "\n",
    "Audiodata_train = {'percentile_25': [], 'percentile_50': [], 'percentile_75': [], 'percentile_90': [], 'mfcc': [], 'sc':[], 'label': []}\n",
    "\n",
    "for (info, label) in zip(X_train_init.values, y_train_init.values):\n",
    "\n",
    "    data = info[0]\n",
    "    timestamps = info[1]\n",
    "\n",
    "    data = preprocess_data(data)\n",
    "    \n",
    "    # Extracting coughs/others\n",
    "    for timestamp in timestamps:\n",
    "\n",
    "        start = int((timestamp - timestamp_range_min) * sample_rate)\n",
    "        finish = int((timestamp + timestamp_range_max) * sample_rate)\n",
    "\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "\n",
    "        if finish > len(data):\n",
    "            finish = len(data) - 1\n",
    "\n",
    "        extracted_data = data[start:finish]\n",
    "        \n",
    "        if (len(extracted_data) != data_shape):\n",
    "            continue\n",
    "                            \n",
    "        # Find percentile points\n",
    "        per_25, per_50, per_75, per_90 = find_percentile_points(extracted_data)\n",
    "\n",
    "        # MFCC Feature extraction\n",
    "        mfccs, delta_mfccs, delta2_mfccs = get_mfcc_features(extracted_data)\n",
    "\n",
    "        # Comprehensive MFCCs  \n",
    "        comprehensive_mfccs = np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
    "\n",
    "        # Find spectral centroids\n",
    "        sc = librosa.feature.spectral_centroid(y=extracted_data, sr=sample_rate)\n",
    "\n",
    "        Audiodata_train['percentile_25'].append(per_25)\n",
    "        Audiodata_train['percentile_50'].append(per_50)\n",
    "        Audiodata_train['percentile_75'].append(per_75)\n",
    "        Audiodata_train['percentile_90'].append(per_90)\n",
    "        Audiodata_train['mfcc'].append(comprehensive_mfccs)            \n",
    "        Audiodata_train['sc'].append(sc)\n",
    "        Audiodata_train['label'].append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfecef",
   "metadata": {},
   "source": [
    "## Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b39ca3d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data \n",
      "\n",
      "-------------------\n",
      "   percentile_25  percentile_50  percentile_75  percentile_90  \\\n",
      "0     136.666667    1953.333333    6716.666667   15406.666667   \n",
      "1     103.333333     666.666667    2636.666667   11820.000000   \n",
      "2      86.666667     776.666667    4346.666667   14380.000000   \n",
      "3     153.333333    1393.333333    5566.666667   14580.000000   \n",
      "4     163.333333    4550.000000   11016.666667   18050.000000   \n",
      "\n",
      "                                                mfcc  \\\n",
      "0  [[-670.4250312947773, -670.4250312947773, -670...   \n",
      "1  [[-553.9005129480573, -553.9005129480573, -553...   \n",
      "2  [[-532.2531118581925, -532.2531118581925, -532...   \n",
      "3  [[-592.8709546535789, -592.8709546535789, -592...   \n",
      "4  [[-134.16739157378328, -143.78862403286476, -1...   \n",
      "\n",
      "                                                  sc  label  \n",
      "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4180...  other  \n",
      "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2556...  other  \n",
      "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3294...  other  \n",
      "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3419...  other  \n",
      "4  [[3564.377717240006, 3706.9457723172354, 3980....  other  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Converting the Audiodata dictionary into the pandas dataframe\n",
    "\n",
    "# Train data\n",
    "\n",
    "df_train = pd.DataFrame.from_dict(Audiodata_train)\n",
    "\n",
    "print(\"Train Data \\n\")\n",
    "print(\"-------------------\")\n",
    "print(df_train.head())\n",
    "print()\n",
    "\n",
    "mfcc_values = np.array(df_train['mfcc'].tolist())\n",
    "mfcc_values = mfcc_values.reshape(mfcc_values.shape[0], -1)\n",
    "\n",
    "sc_values = np.array(df_train['sc'].tolist())\n",
    "sc_values = sc_values.reshape(sc_values.shape[0], -1)\n",
    "\n",
    "percentile_values = df_train.iloc[:, :4].values\n",
    "\n",
    "X_train = np.concatenate((percentile_values, mfcc_values, sc_values), axis=1)\n",
    "X_train_per = percentile_values\n",
    "X_train_per_mfcc =  np.concatenate((percentile_values, mfcc_values), axis=1)\n",
    "X_train_mfcc_sc = np.concatenate((mfcc_values, sc_values), axis=1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = df_train.iloc[:, -1]\n",
    "y_train = 1 - label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "50260047",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a8096",
   "metadata": {},
   "source": [
    "# Extraction and Classification Performance of the Model on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17d595",
   "metadata": {},
   "source": [
    "## Time Domain Sound Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "39b0a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cough Detection Algorithm\n",
    "\n",
    "def detect_coughs_time_domain(data):\n",
    "    \n",
    "    max_value = np.max(data)\n",
    "    mean_value = np.mean(data)\n",
    "    std = np.std(data)\n",
    "\n",
    "    # Threshold \n",
    "    percentile_threshold = 90\n",
    "    threshold = np.percentile(data, percentile_threshold)\n",
    "\n",
    "    # Peak detection\n",
    "    cough_indices, _ = find_peaks(data, prominence = 0.3)\n",
    "    cough_indices = list(cough_indices)\n",
    "\n",
    "    # Deleting overlaps in the peaks - Avoiding to count same cough more than one\n",
    "    i = 0\n",
    "    while i < len(cough_indices):\n",
    "\n",
    "        peak = cough_indices[i]\n",
    "        peak_range = (peak - 5000, peak + 5000) # The range is determined experimentally\n",
    "\n",
    "        overlap_indices = [index for index in cough_indices\n",
    "                       if peak_range[0] < index < peak_range[1]]\n",
    "\n",
    "        if len(overlap_indices) > 1:\n",
    "\n",
    "            # Find the index with maximum amplitude \n",
    "            max = overlap_indices[0]\n",
    "            for index in overlap_indices:\n",
    "                if (data[index] > data[max]):\n",
    "                    max = index\n",
    "\n",
    "            overlap_indices.remove(max)\n",
    "\n",
    "            for element in overlap_indices:\n",
    "                cough_indices.remove(element)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    # Applying the threshold\n",
    "    cough_indices_copy = cough_indices.copy()\n",
    "    for index in cough_indices_copy:\n",
    "\n",
    "        amplitude = data[index]\n",
    "\n",
    "        if (amplitude < threshold):\n",
    "            cough_indices.remove(index)\n",
    "\n",
    "\n",
    "    # Finding the timestamps of the coughs\n",
    "    predicted_timestamps = []\n",
    "    for index in cough_indices:\n",
    "        predicted_timestamps.append(round(index / sample_rate, 6))\n",
    "\n",
    "\n",
    "    # Filtering the sound after coughing\n",
    "    for ts in predicted_timestamps:\n",
    "        matches = list((ts_2 for ts_2 in predicted_timestamps if ts < ts_2 < ts + 0.4))\n",
    "\n",
    "        if len(matches) != 0:\n",
    "            for i in range(len(matches)):\n",
    "                index = predicted_timestamps.index(matches[i])\n",
    "                predicted_timestamps.remove(matches[i])\n",
    "                cough_indices.remove(cough_indices[index])\n",
    "\n",
    "    return cough_indices, predicted_timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b80ac0",
   "metadata": {},
   "source": [
    "## Frequency Domain Sound Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7dc7b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summation of the frequency bins in a spectogram\n",
    "\n",
    "def get_frequency_sums(mel_spectrogram_db):\n",
    "    \n",
    "    sums = []\n",
    "    S_db_tp = np.transpose(mel_spectrogram_db)\n",
    "\n",
    "    for bin in S_db_tp:\n",
    "        sums.append(np.sum(bin))\n",
    "\n",
    "    sums = np.array(sums)\n",
    "\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0c39a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_coughs_freq_domain(data, percentile_threshold = 90):\n",
    "    \n",
    "    duration = len(data) / sample_rate\n",
    "    \n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=data, sr=sample_rate)\n",
    "    mel_spectrogram_db = librosa.amplitude_to_db(mel_spectrogram, ref=np.max)    \n",
    "    \n",
    "    frequency_sums = get_frequency_sums(mel_spectrogram_db)\n",
    "    \n",
    "    # Threshold \n",
    "    threshold = np.percentile(frequency_sums, percentile_threshold)\n",
    "    \n",
    "    # Peak detection\n",
    "    cough_indices, _ = find_peaks(frequency_sums, prominence = 0.3)\n",
    "    cough_indices = list(cough_indices)\n",
    "    \n",
    "    # Deleting overlaps in the peaks - Avoiding to count same cough more than one\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(cough_indices):\n",
    "\n",
    "        peak = cough_indices[i]\n",
    "        peak_range = (peak - 50, peak + 50) # The range is determined experimentally\n",
    "\n",
    "        overlap_indices = [index for index in cough_indices\n",
    "                       if peak_range[0] < index < peak_range[1]]\n",
    "\n",
    "        if len(overlap_indices) > 1:\n",
    "\n",
    "            # Find the index with maximum amplitude \n",
    "            max = overlap_indices[0]\n",
    "            for index in overlap_indices:\n",
    "                if (frequency_sums[index] > frequency_sums[max]):\n",
    "                    max = index\n",
    "\n",
    "            overlap_indices.remove(max)\n",
    "\n",
    "            for element in overlap_indices:\n",
    "                cough_indices.remove(element)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # Applying the threshold\n",
    "    cough_indices_copy = list(cough_indices)\n",
    "    for index in cough_indices_copy: \n",
    "        amplitude = frequency_sums[index]\n",
    "        if amplitude < threshold:\n",
    "            cough_indices.remove(index)\n",
    "    \n",
    "    # Finding the timestamps of the coughs\n",
    "    predicted_timestamps = []\n",
    "    \n",
    "    total_samples = len(data)\n",
    "    data_length = len(frequency_sums)\n",
    "    \n",
    "    # Finding the timestamps of the coughs\n",
    "    for index in cough_indices:\n",
    "        \n",
    "        actual_index = total_samples * index / data_length\n",
    "        actual_timestamp = round(actual_index / sample_rate, 6)\n",
    "        \n",
    "        predicted_timestamps.append(actual_timestamp)\n",
    "    \n",
    "    # Filtering the sound after coughing\n",
    "    for ts in predicted_timestamps:\n",
    "        match = list((ts_2 for ts_2 in predicted_timestamps if ts < ts_2 < ts + 0.4))\n",
    "        if len(match) != 0:\n",
    "            index = predicted_timestamps.index(match[0])\n",
    "            predicted_timestamps.remove(match[0])\n",
    "            cough_indices.remove(cough_indices[index])\n",
    "\n",
    "    \n",
    "    return cough_indices, predicted_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7fa07f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_coughs(preprocessed_data, model):\n",
    "\n",
    "    # Extraction of high frequency signals (cough/other) from the audio\n",
    "    audio_peak_extractions = []\n",
    "    \n",
    "    # Time-based and frequency-based extractions\n",
    "    cough_indices_time, predicted_timestamps_time = detect_coughs_time_domain(preprocessed_data)\n",
    "    cough_indices_freq, predicted_timestamps_freq = detect_coughs_freq_domain(preprocessed_data)\n",
    "\n",
    "    predicted_timestamps = []\n",
    "\n",
    "    # Getting predicted timestamps by comparing time-based and frequency-based extractions\n",
    "\n",
    "    for timestamp in predicted_timestamps_freq:\n",
    "\n",
    "        if any(timestamp - 0.15 < element < timestamp + 0.15 for element in predicted_timestamps_time):\n",
    "\n",
    "            predicted_timestamps.append(timestamp)\n",
    "        \n",
    "    # Getting the extracted data\n",
    "    for timestamp in predicted_timestamps:\n",
    "\n",
    "        start = int((timestamp - timestamp_range_min) * sample_rate)\n",
    "        finish = int((timestamp + timestamp_range_max) * sample_rate)\n",
    "\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "\n",
    "        if finish > len(preprocessed_data):\n",
    "            finish = len(preprocessed_data) - 1\n",
    "\n",
    "        extracted_data = preprocessed_data[start:finish]\n",
    "    \n",
    "        # Add padding or truncate if necessary\n",
    "        if len(extracted_data) < data_shape:\n",
    "            \n",
    "            padding_size = data_shape - len(extracted_data)\n",
    "            left_padding = padding_size // 2\n",
    "            right_padding = padding_size - left_padding\n",
    "\n",
    "            extracted_data = np.pad(extracted_data, (left_padding, right_padding), mode='constant', constant_values=0)\n",
    "\n",
    "        elif len(extracted_data) > data_shape:\n",
    "            extracted_data = extracted_data[:data_shape]\n",
    "\n",
    "        audio_peak_extractions.append((extracted_data, timestamp))\n",
    "    \n",
    "    # Getting features of the extracted audio data\n",
    "    Audiodata_new = {'percentile_25': [], 'percentile_50': [], 'percentile_75': [], 'percentile_90': [], 'mfcc': [], 'sc':[]}\n",
    "    \n",
    "    for peak, timestamp in audio_peak_extractions:\n",
    "\n",
    "        # Percentile Calculation\n",
    "        per_25, per_50, per_75, per_90 = find_percentile_points(peak)\n",
    "\n",
    "\n",
    "        # MFCC Feature extraction\n",
    "        mfccs, delta_mfccs, delta2_mfccs = get_mfcc_features(peak)\n",
    "\n",
    "        # Comprehensive MFCCs\n",
    "        comprehensive_mfccs = np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
    "\n",
    "        # Find spectral centroids\n",
    "        sc = librosa.feature.spectral_centroid(y=peak, sr=sample_rate)\n",
    "\n",
    "        Audiodata_new['percentile_25'].append(per_25)\n",
    "        Audiodata_new['percentile_50'].append(per_50)\n",
    "        Audiodata_new['percentile_75'].append(per_75)\n",
    "        Audiodata_new['percentile_90'].append(per_90)\n",
    "        Audiodata_new['mfcc'].append(comprehensive_mfccs)\n",
    "        Audiodata_new['sc'].append(sc)\n",
    "\n",
    "\n",
    "    df_new = pd.DataFrame.from_dict(Audiodata_new)\n",
    "    \n",
    "    try:\n",
    "    # Both MFCCs and Percentiles\n",
    "        mfcc_values = np.array(df_new['mfcc'].tolist())\n",
    "        mfcc_values = mfcc_values.reshape(mfcc_values.shape[0], -1)\n",
    "\n",
    "        sc_values = np.array(df_new['sc'].tolist())\n",
    "        sc_values = sc_values.reshape(sc_values.shape[0], -1)\n",
    "\n",
    "        percentile_values = df_new.iloc[:, :4].values\n",
    "\n",
    "        new_data = np.concatenate((percentile_values, mfcc_values, sc_values), axis=1)    \n",
    "        prediction = model.predict(new_data)\n",
    "\n",
    "        final_prediction = []\n",
    "\n",
    "        for i in range(len(predicted_timestamps)):\n",
    "            if (prediction[i] == 1):\n",
    "                final_prediction.append(predicted_timestamps[i])\n",
    "\n",
    "        #print(f\"P Timestamps: {predicted_timestamps}\")\n",
    "        return final_prediction\n",
    "    \n",
    "    except: \n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4840bad",
   "metadata": {},
   "source": [
    "# Prediction and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "319f75b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.903657, 1.288308, 1.673156, 3.463981, 3.922...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.001159668, 0.0012512207, 0.001159668, 0.001...</td>\n",
       "      <td>[1.516739, 6.591125, 7.126444, 12.228711, 21.0...</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.950024, 4.308214, 5.214044, 5.867127]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.033416748, 0.044677734, 0.048095703, 0.0523...</td>\n",
       "      <td>[2.530975, 11.993107, 39.288163, 51.734059]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-0.0004272461, -0.00048828125, -0.00061035156...</td>\n",
       "      <td>[4.007188, 6.963311, 12.021565, 23.231565, 27....</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.012420654, 0.025421143, 0.030853271, 0.0290...</td>\n",
       "      <td>[2.233332, 3.304087, 11.01195, 23.563642]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.006500244, 0.0027160645, -0.0010986328, -0....</td>\n",
       "      <td>[3.297234, 11.052698, 18.761723]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[-0.003540039, -0.0073242188, -0.008422852, -0...</td>\n",
       "      <td>[39.404319]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.026062012, 0.055114746, 0.068359375, 0.0686...</td>\n",
       "      <td>[1.182263, 26.327739]</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                audio  \\\n",
       "31  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "41  [0.001159668, 0.0012512207, 0.001159668, 0.001...   \n",
       "27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "25  [0.033416748, 0.044677734, 0.048095703, 0.0523...   \n",
       "6   [-0.0004272461, -0.00048828125, -0.00061035156...   \n",
       "9   [0.012420654, 0.025421143, 0.030853271, 0.0290...   \n",
       "4   [0.006500244, 0.0027160645, -0.0010986328, -0....   \n",
       "33  [-0.003540039, -0.0073242188, -0.008422852, -0...   \n",
       "39  [0.026062012, 0.055114746, 0.068359375, 0.0686...   \n",
       "\n",
       "                                           timestamps  label  \n",
       "31  [0.903657, 1.288308, 1.673156, 3.463981, 3.922...  cough  \n",
       "41  [1.516739, 6.591125, 7.126444, 12.228711, 21.0...  cough  \n",
       "27           [3.950024, 4.308214, 5.214044, 5.867127]  cough  \n",
       "25        [2.530975, 11.993107, 39.288163, 51.734059]  cough  \n",
       "6   [4.007188, 6.963311, 12.021565, 23.231565, 27....  cough  \n",
       "9           [2.233332, 3.304087, 11.01195, 23.563642]  cough  \n",
       "4                    [3.297234, 11.052698, 18.761723]  cough  \n",
       "33                                        [39.404319]  cough  \n",
       "39                              [1.182263, 26.327739]  cough  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data loading\n",
    "\n",
    "audio_data_test = X_test_init.copy()\n",
    "\n",
    "audio_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "945e86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(models_list, model_hyperparameters):\n",
    "    \n",
    "    results = []\n",
    "    model_keys = list(model_hyperparameters.keys())\n",
    "    \n",
    "    for i in range(len(models_list)):\n",
    "        \n",
    "        key = model_keys[i]\n",
    "        params = model_hyperparameters[key]\n",
    "        \n",
    "        classifier = GridSearchCV(models_list[i], params, cv=5, scoring='f1')\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        results.append({\n",
    "            'model used': models_list[i],\n",
    "            'highest score': classifier.best_score_,\n",
    "            'best hyperparameters': classifier.best_params_,\n",
    "            \n",
    "        })\n",
    "\n",
    "    \n",
    "    result_dataframe = pd.DataFrame(results, columns = ['model used', 'highest score', 'best hyperparameters'])    \n",
    "    return result_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5d1427a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Models: \n",
    "\n",
    "0                                           SVC(C=0.5)\n",
    "1    KNeighborsClassifier(n_neighbors=161, weights=...\n",
    "2    (DecisionTreeClassifier(max_features='sqrt', r...\n",
    "3      GaussianNB(var_smoothing=5.336699231206313e-07)\n",
    "\n",
    "\"\"\"\n",
    "models_list = [SVC(), KNeighborsClassifier(), RandomForestClassifier(random_state=0), GaussianNB()]\n",
    "\n",
    "\n",
    "model_hyperparameters = {\n",
    "\n",
    "    'svc_hyperparameters': {\n",
    "        \n",
    "        'C': [0.5, 1, 10, 100],\n",
    "        'gamma': ['scale', 1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'kernel': ['rbf']\n",
    "        \n",
    "    },\n",
    "    \n",
    "    'KNN_hyperparameters': {\n",
    "        \n",
    "        'n_neighbors': list(range(3, int(len(X_train) * 0.65),2)),\n",
    "        'weights': ['uniform', 'distance']\n",
    "\n",
    "    },\n",
    "    \n",
    "    'random_forest_hyperparameters': {\n",
    "        \n",
    "        'n_estimators': [10, 20, 50, 100]\n",
    "    },\n",
    "    \n",
    "    'naive_bayes_hyperparameters': {\n",
    "    \n",
    "        'var_smoothing': np.logspace(0,-9, num=100)\n",
    "    },\n",
    "        \n",
    "}\n",
    "\n",
    "result_df = model_selection(models_list, model_hyperparameters)\n",
    "\n",
    "for model_info in result_df.values:\n",
    "    \n",
    "    model = model_info[0]\n",
    "    best_params = model_info[2]\n",
    "    \n",
    "    model.set_params(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "model_list = result_df['model used']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6663c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_and_real_timestamps = {'real': [], 'predicted': []}\n",
    "\n",
    "for row in audio_data_test.values:\n",
    "\n",
    "    data = row[0]\n",
    "    timestamps = row[1]\n",
    "\n",
    "    data = preprocess_data(data)\n",
    "\n",
    "    #print(f\"R Timestamps: {timestamps}\")\n",
    "    detected_cough_timestamps = detect_coughs(data, model)\n",
    "    #print()\n",
    "\n",
    "    predicted_and_real_timestamps['real'].append(timestamps)\n",
    "    predicted_and_real_timestamps['predicted'].append(detected_cough_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3eb67c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(weights='distance')\n",
      "-----------------------------\n",
      "The F1 score of KNeighborsClassifier(weights='distance'): 0.69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN Prediction\n",
    "\n",
    "model = models_list[1]\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "print(model)\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "\n",
    "    \n",
    "pr_df = pd.DataFrame.from_dict(predicted_and_real_timestamps)\n",
    "\n",
    "for row in pr_df.values:\n",
    "\n",
    "    real_timestamps = row[0]\n",
    "    predicted_timestamps = row[1]\n",
    "\n",
    "    real_timestamps.sort()\n",
    "    predicted_timestamps.sort()\n",
    "\n",
    "    #plt.figure(figsize=(6, 3))\n",
    "\n",
    "    for real, pred in zip(real_timestamps, predicted_timestamps):\n",
    "        if any(real - 0.15 < p < real + 0.15 for p in predicted_timestamps):\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "        if not any(pred - 0.15 < r < pred + 0.15 for r in real_timestamps):\n",
    "            fp += 1\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "f1 = 2 * recall * precision / (recall + precision)\n",
    "\n",
    "print(f\"The F1 score of {model}: {round(f1,3)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b7437408",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100)\n",
      "-----------------------------\n",
      "The F1 score of SVC(C=100): 0.679\n",
      "\n",
      "KNeighborsClassifier(weights='distance')\n",
      "-----------------------------\n",
      "The F1 score of KNeighborsClassifier(weights='distance'): 0.69\n",
      "\n",
      "RandomForestClassifier(random_state=0)\n",
      "-----------------------------\n",
      "The F1 score of RandomForestClassifier(random_state=0): 0.69\n",
      "\n",
      "GaussianNB(var_smoothing=2.310129700083158e-08)\n",
      "-----------------------------\n",
      "The F1 score of GaussianNB(var_smoothing=2.310129700083158e-08): 0.679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in model_list: \n",
    "        \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    print(model)\n",
    "    print(\"-----------------------------\")\n",
    "    \n",
    "    predicted_and_real_timestamps = {'real': [], 'predicted': []}\n",
    "\n",
    "    for row in audio_data_test.values:\n",
    "\n",
    "        data = row[0]\n",
    "        timestamps = row[1]\n",
    "\n",
    "        data = preprocess_data(data)\n",
    "\n",
    "        #print(f\"R Timestamps: {timestamps}\")\n",
    "        detected_cough_timestamps = detect_coughs(data, model)\n",
    "        #print()\n",
    "\n",
    "        predicted_and_real_timestamps['real'].append(timestamps)\n",
    "        predicted_and_real_timestamps['predicted'].append(detected_cough_timestamps)\n",
    "\n",
    "    \"\"\"2\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Real\")\n",
    "    plt.plot(time, data, label='Signal')\n",
    "    plt.scatter(timestamps, np.zeros_like(timestamps), marker='o', color='red', label='Real Timestamps', s=10, zorder=5)\n",
    "\n",
    "    # Plot predicted timestamps\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.plot(time, data, label='Signal')\n",
    "    plt.scatter(detected_cough_timestamps, np.zeros_like(detected_cough_timestamps), marker='o', color='red', label='Predicted Timestamps', s=10, zorder=5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print()\n",
    "    \"\"\"\n",
    "\n",
    "    pr_df = pd.DataFrame.from_dict(predicted_and_real_timestamps)\n",
    "\n",
    "    for row in pr_df.values:\n",
    "\n",
    "        real_timestamps = row[0]\n",
    "        predicted_timestamps = row[1]\n",
    "\n",
    "        real_timestamps.sort()\n",
    "        predicted_timestamps.sort()\n",
    "        \n",
    "        #plt.figure(figsize=(6, 3))\n",
    "\n",
    "        for real, pred in zip(real_timestamps, predicted_timestamps):\n",
    "            if any(real - 0.15 < p < real + 0.15 for p in predicted_timestamps):\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "\n",
    "            if not any(pred - 0.15 < r < pred + 0.15 for r in real_timestamps):\n",
    "                fp += 1\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    f1 = 2 * recall * precision / (recall + precision)\n",
    "\n",
    "    print(f\"The F1 score of {model}: {round(f1,3)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f95e6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

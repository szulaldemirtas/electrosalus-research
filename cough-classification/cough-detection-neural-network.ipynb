{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4e33d8",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1073a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspectrogram(data):\n",
    "    \n",
    "    melspec = librosa.feature.melspectrogram(y = data,\n",
    "                                                  sr = sample_rate, \n",
    "                                                  n_fft = 512, \n",
    "                                                  hop_length = 256, \n",
    "                                                  n_mels = 40).T\n",
    "\n",
    "    melspec = librosa.power_to_db(melspec)\n",
    "    \n",
    "    return melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69559bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a3cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2):\n",
    "        \n",
    "    n_mels, n_steps = spec.shape\n",
    "    mask_value = spec.mean()\n",
    "    aug_spec = spec\n",
    "\n",
    "    freq_mask_param = max_mask_pct * n_mels\n",
    "    for _ in range(n_freq_masks):\n",
    "      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    time_mask_param = max_mask_pct * n_steps\n",
    "    for _ in range(n_time_masks):\n",
    "      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    return aug_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59718309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "mel_train, mel_valid, mel_train_label, mel_valid_label = train_test_split(df_train_extracted['data'], df_train_extracted['label'], train_size=0.80)\n",
    "\n",
    "# Function to process data and apply augmentation\n",
    "def process_data(data, label):\n",
    "    melspec = torch.tensor(get_melspectrogram(data))\n",
    "    augmented_spec = torch.tensor(spectro_augment(melspec))\n",
    "    return melspec, augmented_spec, label\n",
    "\n",
    "# Train data spectrograms\n",
    "mel_train_spec = []\n",
    "mel_train_spec_label = []\n",
    "\n",
    "for data, label in zip(mel_train, mel_train_label):\n",
    "    melspec, augmented_spec, label = process_data(data, label)\n",
    "    mel_train_spec.append(melspec)\n",
    "    mel_train_spec.append(augmented_spec)\n",
    "    mel_train_spec_label.extend([label, label])\n",
    "\n",
    "# Validation data spectrograms \n",
    "mel_valid_spec = []\n",
    "mel_valid_spec_label = []\n",
    "\n",
    "for data, label in zip(mel_valid, mel_valid_label):\n",
    "    melspec, _, label = process_data(data, label)\n",
    "    mel_valid_spec.append(melspec)\n",
    "    mel_valid_spec_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27220193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpecDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        spec = self.dataframe.loc[idx, 'data']\n",
    "        label = self.dataframe.loc[idx, 'label']\n",
    "        return spec, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {\n",
    "    'data': mel_train_spec,\n",
    "    'label': mel_train_spec_label\n",
    "}\n",
    "\n",
    "valid_data = {\n",
    "    'data': mel_valid_spec,\n",
    "    'label': mel_valid_spec_label\n",
    "}\n",
    "\n",
    "df_mel_train = pd.DataFrame.from_dict(train_data)\n",
    "df_mel_valid = pd.DataFrame.from_dict(valid_data)\n",
    "\n",
    "train_ds = MelSpecDataset(df_mel_train)\n",
    "valid_ds = MelSpecDataset(df_mel_valid)\n",
    "\n",
    "print(df_mel_train.head())\n",
    "print()\n",
    "print(df_mel_valid.head())\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395226bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Classification Model\n",
    "\n",
    "class AudioClassifier (nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_layers = []\n",
    "\n",
    "        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\n",
    "        self.conv1 = nn.Conv2d(16, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
    "        self.conv2.bias.data.zero_()\n",
    "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
    "        self.conv3.bias.data.zero_()\n",
    "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
    "        self.conv4.bias.data.zero_()\n",
    "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
    "\n",
    "        # Linear Classifier\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "        # Wrap the Convolutional Blocks\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    " \n",
    "    # ----------------------------\n",
    "    # Forward pass computations\n",
    "    # ----------------------------\n",
    "    def forward(self, x):\n",
    "        # Run the convolutional blocks\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # Adaptive pool and flatten for input to linear layer\n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Linear layer\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Final output\n",
    "        return x\n",
    "\n",
    "# Create the model and put it on the GPU if available\n",
    "myModel = AudioClassifier()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "myModel = myModel.to(device)\n",
    "# Check that it is on Cuda\n",
    "next(myModel.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85b2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def training(model, train_dl, num_epochs):\n",
    "  # Loss Function, Optimizer and Scheduler\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs,\n",
    "                                                anneal_strategy='linear')\n",
    "\n",
    "  # Repeat for each epoch\n",
    "  for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    # Repeat for each batch in the training set\n",
    "    for i, data in enumerate(train_dl):\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1]\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        \n",
    "        label_mapping = {'cough': 1, 'other': 0}\n",
    "        label_tensor = torch.tensor([label_mapping[label] for label in labels], dtype=torch.long).to(device)\n",
    "\n",
    "        # Normalize the inputs\n",
    "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "        inputs = (inputs - inputs_m) / inputs_s\n",
    "        \n",
    "        inputs = inputs.float().to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Keep stats for Loss and Accuracy\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Get the predicted class with the highest score\n",
    "        _, prediction = torch.max(outputs,1)\n",
    "        # Count of predictions that matched the target label\n",
    "        correct_prediction += (prediction == labels).sum().item()\n",
    "        total_prediction += prediction.shape[0]\n",
    "\n",
    "        #if i % 10 == 0:    # print every 10 mini-batches\n",
    "        #    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "    \n",
    "    # Print stats at the end of the epoch\n",
    "    num_batches = len(train_dl)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
    "\n",
    "  print('Finished Training')\n",
    "  \n",
    "num_epochs=2   # Just for demo, adjust this higher.\n",
    "\n",
    "training(myModel, train_dl, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

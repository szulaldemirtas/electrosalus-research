{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c2142",
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(f\"R Timestamps: {timestamps}\")\n",
    "        \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Real\")\n",
    "    plt.plot(time, data, label='Signal')\n",
    "    plt.scatter(timestamps, np.zeros_like(timestamps), marker='o', color='red', label='Real Timestamps', s=10, zorder=5)\n",
    "\n",
    "    # Plot predicted timestamps\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.plot(time, data, label='Signal')\n",
    "    plt.scatter(detected_cough_timestamps, np.zeros_like(detected_cough_timestamps), marker='o', color='red', label='Predicted Timestamps', s=10, zorder=5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec64db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of high frequency signals (cough/other) from the audio\n",
    "\n",
    "\n",
    "audio_files = []\n",
    "audio_files.extend(os.listdir('./audio-records/test-records'))\n",
    "audio_peak_extractions = dict()\n",
    "\n",
    "# Removing irrelevant files\n",
    "for file in audio_files.copy():\n",
    "    if not file.endswith('.wav'):\n",
    "        audio_files.remove(file)\n",
    "\n",
    "\n",
    "for file in audio_files:\n",
    "\n",
    "    file_path = './audio-records/test-records/' + file\n",
    "\n",
    "    if file not in audio_peak_extractions:\n",
    "        audio_peak_extractions[file] = []\n",
    "    \n",
    "    # Loading audio_file\n",
    "    # Target sample rate: 48000\n",
    "    data, sample_rate = librosa.load(file_path, sr=48000)\n",
    "\n",
    "    # Audio duration\n",
    "    duration = librosa.get_duration(path = file_path)\n",
    "    total_samples = duration * sample_rate\n",
    "    time = np.arange(0, len(data)) / sample_rate\n",
    "\n",
    "    # Filtering data\n",
    "    data = butter_bandpass_filter(data, 1000, 4000, sample_rate, 8)\n",
    "\n",
    "    # Getting moving average of the data\n",
    "    moving_avg_data = compute_moving_average(np.abs(data))\n",
    "\n",
    "    # Normalize the data\n",
    "    normalized_moving_avg_data = normalize_data(moving_avg_data)\n",
    "    \n",
    "    # Getting melspectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=normalized_moving_avg_data, sr=sample_rate)\n",
    "    mel_spectrogram_db = librosa.amplitude_to_db(mel_spectrogram, ref=np.max)    \n",
    "\n",
    "    frequency_sums = get_frequency_sums(mel_spectrogram_db)\n",
    "    \n",
    "    # Detection of high frequency sounds - peaks (Based on frequency domain)\n",
    "    peak_indices_freq , predicted_timestamps_freq = detect_coughs_freq_domain(frequency_sums, file_path)\n",
    "    \n",
    "    # Detection of sounds with high magnitude (Based on time domain)\n",
    "    peak_indices_time , predicted_timestamps_time = detect_coughs_time_domain(normalized_moving_avg_data)\n",
    "    \n",
    "    predicted_timestamps = []\n",
    "    \n",
    "    for timestamp in predicted_timestamps_freq:\n",
    "        \n",
    "        if any(timestamp - 0.15 < element < timestamp + 0.15 for element in predicted_timestamps_time):\n",
    "            \n",
    "            predicted_timestamps.append(timestamp)\n",
    "        \n",
    "    \n",
    "    plt.plot(normalized_moving_avg_data)\n",
    "    for timestamp in predicted_timestamps:\n",
    "        \n",
    "        start = int((timestamp - 0.1) * sample_rate)\n",
    "        finish = int((timestamp + 0.3) * sample_rate)\n",
    "        \n",
    "        plt.scatter([start,finish], [0,0], color='red', zorder=5)    \n",
    "        audio_peak_extractions[file].append((normalized_moving_avg_data[start:finish], timestamp))\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5849d328",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#---------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# KNN - Only Percentiles\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train_per, y_train_per)\n\u001b[1;32m      7\u001b[0m best_params_per \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_params_per))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# KNN - Only Percentiles\n",
    "# Define the model\n",
    "\n",
    "grid_search.fit(X_train_per, y_train_per)\n",
    "best_params_per = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters: {}\".format(best_params_per))\n",
    "clf_knn_per = KNeighborsClassifier(**best_params_per)\n",
    "clf_knn_per.fit(X_train_per, y_train_per)\n",
    "\n",
    "y_pred_per = clf_knn_per.predict(X_test_per)\n",
    "cm_per = confusion_matrix(y_test_per, y_pred_per)\n",
    "\n",
    "f1_per = f1_score(y_test_per, y_pred_per)\n",
    "\n",
    "print(\"F1 Score: {}\".format(f1_per))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_per, display_labels=display_labels)\n",
    "disp.plot()\n",
    "plt.title(\"KNN - Percentiles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fec78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "        copy_data = moving_avg_data.copy()\n",
    "    coughs = []\n",
    "\n",
    "    for timestamp in real_timestamps:\n",
    "\n",
    "        start = int((timestamp - timestamp_range_min) * sample_rate)\n",
    "        finish = int((timestamp + timestamp_range_max) * sample_rate)\n",
    "        \n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        \n",
    "        if finish > int(total_samples):\n",
    "            finish = int(total_samples) - 1\n",
    "\n",
    "        data = copy_data[start:finish]\n",
    "        \n",
    "        if (data.shape[0] != data_shape):\n",
    "            continue\n",
    "        \n",
    "        coughs.append(data)\n",
    "\n",
    "    # *******************************\n",
    "    for cough in coughs:\n",
    "        # Removing DC component\n",
    "        cough -= np.mean(cough)\n",
    "        all_cough_data.append(cough)\n",
    "\n",
    "        try:\n",
    "            \n",
    "            # Find percentile points\n",
    "            per_25, per_50, per_75, per_90 = find_percentile_points(cough)\n",
    "\n",
    "            Audiodata['percentile_25'].append(per_25)\n",
    "            Audiodata['percentile_50'].append(per_50)\n",
    "            Audiodata['percentile_75'].append(per_75)\n",
    "            Audiodata['percentile_90'].append(per_90)\n",
    "\n",
    "            Audiodata_stat['percentile_25'].append(per_25)\n",
    "            Audiodata_stat['percentile_50'].append(per_50)\n",
    "            Audiodata_stat['percentile_75'].append(per_75)\n",
    "            Audiodata_stat['percentile_90'].append(per_90)\n",
    "\n",
    "            # MFCC Feature extraction\n",
    "            mfccs, delta_mfccs, delta2_mfccs = get_mfcc_features(cough)\n",
    "\n",
    "            # Comprehensive MFCCs  \n",
    "            comprehensive_mfccs = np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
    "            Audiodata['mfcc'].append(comprehensive_mfccs)            \n",
    "            \n",
    "            Audiodata_stat['mfcc_max'].append([np.max(mfccs), np.max(delta_mfccs), np.max(delta2_mfccs)])\n",
    "            Audiodata_stat['mfcc_min'].append([np.min(mfccs), np.min(delta_mfccs), np.min(delta2_mfccs)])\n",
    "            Audiodata_stat['mfcc_mean'].append([np.mean(mfccs), np.mean(delta_mfccs), np.mean(delta2_mfccs)])\n",
    "            Audiodata_stat['mfcc_std'].append([np.std(mfccs), np.std(delta_mfccs), np.std(delta2_mfccs)])\n",
    "            \n",
    "            # Find spectral centroids\n",
    "            sc = librosa.feature.spectral_centroid(y=cough, sr=sample_rate)\n",
    "            Audiodata['sc'].append(sc)\n",
    "            \n",
    "            Audiodata_stat['sc_max'].append(np.max(sc))\n",
    "            Audiodata_stat['sc_min'].append(np.min(sc))\n",
    "            Audiodata_stat['sc_mean'].append(np.mean(sc))\n",
    "            Audiodata_stat['sc_std'].append(np.std(sc))\n",
    "            \n",
    "            # Add labels\n",
    "            Audiodata['label'].append('cough')\n",
    "            Audiodata_stat['label'].append('cough')\n",
    "\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d66a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e6012",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# ----------------------------------------------------------------------\n",
    "# Other Data\n",
    "\n",
    "audio_files_other = os.listdir('./audio-records/no-cough')\n",
    "timestamp_files_other = os.listdir('./audio-records/no-cough-timestamps')\n",
    "all_no_cough_data = [] # Will be used to create mel spectrograms\n",
    "\n",
    "# Filtering irrelevant files\n",
    "audio_files_other = list(filter(lambda x: x.endswith('.wav'), audio_files_other))\n",
    "timestamp_files_other = list(filter(lambda x: x.endswith('.txt'), timestamp_files_other))\n",
    "\n",
    "for file in audio_files_other:\n",
    "\n",
    "    file_name = file.split(\".wav\")[0]    \n",
    "    timestamp_files = [file[0:19] for file in timestamp_files_other]    \n",
    "\n",
    "    # Finding correspoding timestamp file\n",
    "    index = timestamp_files.index(file_name)\n",
    "    timestamp_data = timestamp_files[index]\n",
    "    \n",
    "    file_path = './audio-records/no-cough/' + file\n",
    "    timestamp_path = './audio-records/no-cough-timestamps/' + timestamp_data + '-label.txt'\n",
    "\n",
    "    # Adding timestamps to the list\n",
    "    real_timestamps = get_real_timestamps(timestamp_path)    \n",
    "    \n",
    "    # Loading audio_file\n",
    "    # Target sample rate: 48000\n",
    "    data, sample_rate = librosa.load(file_path, sr=48000)\n",
    "\n",
    "    # Audio duration\n",
    "    duration = librosa.get_duration(path = file_path)\n",
    "    total_samples = duration * sample_rate\n",
    "    time = np.arange(0, len(data)) / sample_rate\n",
    "\n",
    "    # Filtering data\n",
    "    data = butter_bandpass_filter(data, 1000, 4000, sample_rate,8)\n",
    "\n",
    "    # Getting moving average of the data\n",
    "    moving_avg_data = compute_moving_average(np.abs(data))\n",
    "\n",
    "    # Normalize the data\n",
    "    moving_avg_data = normalize_data(moving_avg_data)\n",
    "    \n",
    "    \n",
    "    # *******************************\n",
    "    # Find peaks in the data\n",
    "    copy_data = moving_avg_data.copy()\n",
    "    peaks = []\n",
    "\n",
    "    for timestamp in real_timestamps:\n",
    "\n",
    "        start = int((timestamp - 0.3) * sample_rate)\n",
    "        finish = int((timestamp + 0.3) * sample_rate)\n",
    "\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        \n",
    "        if finish > total_samples:\n",
    "            finish = total_samples - 1\n",
    "\n",
    "        data = copy_data[start:finish]\n",
    "        peaks.append(data)\n",
    "\n",
    "    # *******************************\n",
    "    for peak in peaks:\n",
    "        # Removing DC component\n",
    "        peak -= np.mean(peak)\n",
    "\n",
    "        all_no_cough_data.append(peak)\n",
    "\n",
    "        try:\n",
    "            \n",
    "            # Find percentile points\n",
    "            per_25, per_50, per_75, per_90 = find_percentile_points(peak)\n",
    "\n",
    "            Audiodata['percentile_25'].append(per_25)\n",
    "            Audiodata['percentile_50'].append(per_50)\n",
    "            Audiodata['percentile_75'].append(per_75)\n",
    "            Audiodata['percentile_90'].append(per_90)\n",
    "\n",
    "            # MFCC Feature extraction\n",
    "            mfccs, delta_mfccs, delta2_mfccs = get_mfcc_features(peak)\n",
    "\n",
    "            print(file_path)\n",
    "            print(duration)\n",
    "            print(mfccs.shape)\n",
    "            print(delta_mfccs.shape)\n",
    "            print(delta2_mfccs.shape)\n",
    "            \n",
    "            # Comprehensive MFCCs\n",
    "            comprehensive_mfccs = np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
    "            Audiodata['mfcc'].append(comprehensive_mfccs)\n",
    "            Audiodata['label'].append('other')\n",
    "            print(\"Comprehensive mfcc: {}\".format(comprehensive_mfccs.shape))\n",
    "            \n",
    "            # Find spectral centroids\n",
    "            sc = librosa.feature.spectral_centroid(y=cough, sr=sample_rate)\n",
    "            Audiodata['sc'].append(sc)\n",
    "            print(sc.shape)\n",
    "            print()\n",
    "\n",
    "            \n",
    "        except:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b61697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Audiodata_stat Dictionary\n",
    "\n",
    "df_stat = pd.DataFrame.from_dict(Audiodata_stat)\n",
    "print(df_stat.head())\n",
    "\n",
    "mfcc_stat_max = np.array(df_stat['mfcc_max'].tolist())\n",
    "mfcc_stat_min = np.array(df_stat['mfcc_min'].tolist())\n",
    "mfcc_stat_mean = np.array(df_stat['mfcc_mean'].tolist())\n",
    "mfcc_stat_std = np.array(df_stat['mfcc_std'].tolist())\n",
    "\n",
    "\n",
    "percentile_values_stat = df_stat.iloc[:, :4].values\n",
    "sc_values_stat = df_stat.iloc[: , 8:12]\n",
    "\n",
    "# X and y \n",
    "X_stat = np.concatenate((percentile_values_stat, mfcc_stat_max, mfcc_stat_min, mfcc_stat_mean, mfcc_stat_std, sc_values_stat), axis=1)\n",
    "y_stat = df.iloc[:, -1]\n",
    "\n",
    "\n",
    "class_mapping = {'cough': 1, 'other': 0}\n",
    "y_stat = [class_mapping[label] for label in y_stat]\n",
    "\n",
    "# Training Data\n",
    "X_train_stat, X_test_stat, y_train_stat, y_test_stat = train_test_split(X_stat, y_stat, random_state= 3, train_size=0.80)\n",
    "\n",
    "# Scaling\n",
    "X_train_stat = scale.fit_transform(X_train_stat)\n",
    "X_test_stat = scale.fit_transform(X_test_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f24f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Support Vector Machine\n",
    "\n",
    "# Optimize the parameters\n",
    "# Finding the best value for gamma and regularization parameter\n",
    "\n",
    "# C: regularization parameter\n",
    "param_grid = [\n",
    "    {\n",
    "    'C': [0.5, 1, 10, 100],\n",
    "    'gamma': ['scale', 1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel': ['rbf']\n",
    "    },\n",
    "]\n",
    "\n",
    "optimal_params = GridSearchCV(\n",
    "    SVC(),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "optimal_params.fit(X_train_stat, y_train_stat)\n",
    "C = optimal_params.best_params_['C']\n",
    "gamma = optimal_params.best_params_['gamma']\n",
    "print(\"Best Parameters: {}\".format(optimal_params.best_params_))\n",
    "\n",
    "# Model Training and Prediction\n",
    "clf_svm_stat = SVC(random_state=42, C=C, gamma=gamma)\n",
    "clf_svm_stat.fit(X_train_stat, y_train_stat)\n",
    "\n",
    "y_pred_stat = clf_svm_stat.predict(X_test_stat)\n",
    "\n",
    "cm = confusion_matrix(y_test_stat, y_pred_stat)\n",
    "f1 = f1_score(y_test_stat, y_pred_stat)\n",
    "\n",
    "print(\"F1 Score: {}\".format(f1))\n",
    "\n",
    "display_labels = ['Other', 'Cough']\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "disp.plot()\n",
    "plt.title(\"Support Vector Machine - Percentiles, MFCCs and Spectral Centroids\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN - Percentiles and MFCCs Combined\n",
    "\n",
    "# Train the model using the training set\n",
    "clf_knn_stat = KNeighborsClassifier(p=2)\n",
    "\n",
    "# Hyperparameter tuning based on the validation performance\n",
    "param_grid_knn = [\n",
    "    {\n",
    "    'n_neighbors': list(range(3, int(len(X_train_stat) * 0.65),2)),\n",
    "    'weights': ['uniform', 'distance']\n",
    "    },\n",
    "]\n",
    "\n",
    "# GridSearchCV\n",
    "optimal_params_knn = GridSearchCV(estimator=clf_knn_stat,\n",
    "                                  param_grid=param_grid_knn,\n",
    "                                  cv=3,\n",
    "                                  scoring='f1'\n",
    "                                )\n",
    "\n",
    "optimal_params_knn.fit(X_train_stat, y_train_stat)\n",
    "best_params = optimal_params_knn.best_params_\n",
    "\n",
    "print(\"Best Parameters: {}\".format(best_params))\n",
    "clf_knn_stat = KNeighborsClassifier(**best_params)\n",
    "clf_knn_stat.fit(X_train_stat, y_train_stat)\n",
    "\n",
    "y_pred_stat = clf_knn_stat.predict(X_test_stat)\n",
    "cm = confusion_matrix(y_test_stat, y_pred_stat)\n",
    "f1 = f1_score(y_test_stat, y_pred_stat)\n",
    "\n",
    "print(\"F1 Score: {}\".format(f1))\n",
    "display_labels = ['other', 'cough']\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "disp.plot()\n",
    "plt.title(\"KNN - Percentiles, MFCCs and Spectral Centroids Statistics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fceec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name format\n",
    "def record_audio(directory):\n",
    "\n",
    "    current_time = datetime.now()\n",
    "    formatted_time = current_time.strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "\n",
    "    filename = os.path.join(directory, f\"{formatted_time}.wav\")\n",
    "\n",
    "    def timer(duration):\n",
    "        for remaining in range(duration, 0, -1):\n",
    "            print(f\"Time remaining: {remaining} seconds\", end='\\r')\n",
    "            sleep(1)\n",
    "        print(\"\\nRecording finished.\")\n",
    "\n",
    "    # Sampling frequency\n",
    "    freq = 48000\n",
    "\n",
    "    # Recording duration\n",
    "    duration = 60\n",
    "\n",
    "    print(\"Recording started...\")\n",
    "    timer_thread = threading.Thread(target=timer, args=(duration,))\n",
    "    timer_thread.start()\n",
    "\n",
    "    recording = sd.rec(int(duration * freq), \n",
    "                       samplerate=freq, channels=1, dtype='int16')\n",
    "\n",
    "    # Record audio for the given number of seconds\n",
    "    sd.wait()\n",
    "    timer_thread.join()\n",
    "\n",
    "    # Convert the NumPy array to audio file\n",
    "    wv.write(filename, recording, freq, sampwidth=2)\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cough audio loading\n",
    "\n",
    "# Target sample rate: 48000\n",
    "filename = record_audio(\"./audio-records/python-recordings/\")\n",
    "recorded_data, sample_rate = librosa.load(filename, sr=48000)\n",
    "\n",
    "Audio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159233d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e57f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of high frequency signals (cough/other) from the audio\n",
    "audio_peak_extractions = []\n",
    "\n",
    "# Filtering data\n",
    "recorded_data = butter_bandpass_filter(recorded_data, 1000, 4000, sample_rate,8)\n",
    "\n",
    "# Getting moving average of the data\n",
    "recorded_data = compute_moving_average(np.abs(recorded_data))\n",
    "\n",
    "# Scaling data\n",
    "recorded_data = recorded_data.reshape(-1,1)    \n",
    "scaler = preprocessing.StandardScaler().fit(recorded_data)\n",
    "recorded_data = scaler.transform(recorded_data)\n",
    "\n",
    "# Normalize data\n",
    "recorded_data = normalize_data(recorded_data)\n",
    "recorded_data = recorded_data.flatten()\n",
    "    \n",
    "# Time \n",
    "time = np.arange(0, len(recorded_data)) / sample_rate\n",
    "\n",
    "# Getting melspectrogram\n",
    "mel_spectrogram = librosa.feature.melspectrogram(y=recorded_data, sr=sample_rate)\n",
    "mel_spectrogram_db = librosa.amplitude_to_db(mel_spectrogram, ref=np.max)    \n",
    "\n",
    "frequency_sums = get_frequency_sums(mel_spectrogram_db)\n",
    "\n",
    "# Detection of high frequency sounds - peaks (Based on frequency domain)\n",
    "peak_indices_freq , predicted_timestamps_freq = detect_coughs_freq_domain(frequency_sums, filename)\n",
    "print(\"Frequency Domain Predicted Timestamps: {}\\n\".format(predicted_timestamps_freq))\n",
    "\n",
    "# Detection of sounds with high magnitude (Based on time domain)\n",
    "peak_indices_time , predicted_timestamps_time = detect_coughs_time_domain(recorded_data)\n",
    "print(\"Time Domain Predicted Timestamps: {}\".format(predicted_timestamps_time))\n",
    "\n",
    "predicted_timestamps = []\n",
    "\n",
    "for timestamp in predicted_timestamps_freq:\n",
    "\n",
    "    if any(timestamp - 0.15 < element < timestamp + 0.15 for element in predicted_timestamps_time):\n",
    "\n",
    "        predicted_timestamps.append(timestamp)\n",
    "\n",
    "print(predicted_timestamps)\n",
    "plt.plot(time, recorded_data)\n",
    "\n",
    "for timestamp in predicted_timestamps:\n",
    "\n",
    "    start = int((timestamp - timestamp_range_min) * sample_rate)\n",
    "    finish = int((timestamp + timestamp_range_max) * sample_rate)\n",
    "\n",
    "    if start < 0:\n",
    "        start = 0\n",
    "\n",
    "    if finish > len(recorded_data):\n",
    "        finish = len(recorded_data) - 1\n",
    "        \n",
    "    plt.scatter([time[start],time[finish]], [0,0], color='red', zorder=5)    \n",
    "    extracted_data = recorded_data[start:finish]\n",
    "    \n",
    "    if len(extracted_data) < data_shape:\n",
    "\n",
    "        padding_size = data_shape - len(extracted_data)\n",
    "        left_padding = padding_size // 2\n",
    "        right_padding = padding_size - left_padding\n",
    "        \n",
    "        extracted_data = np.pad(extracted_data, (left_padding, right_padding), mode='constant', constant_values=0)\n",
    "    \n",
    "    elif len(extracted_data) > data_shape:\n",
    "        extracted_data = extracted_data[:data_shape]\n",
    "    \n",
    "    audio_peak_extractions.append((extracted_data, timestamp))\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdd5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audiodata_new = {'percentile_25': [], 'percentile_50': [], 'percentile_75': [], 'percentile_90': [], 'mfcc': [], 'sc':[]}\n",
    "\n",
    "for peak, timestamp in audio_peak_extractions:\n",
    "    \n",
    "    # Percentile Calculation\n",
    "    per_25, per_50, per_75, per_90 = find_percentile_points(peak)\n",
    "\n",
    "\n",
    "    # MFCC Feature extraction\n",
    "    mfccs, delta_mfccs, delta2_mfccs = get_mfcc_features(peak)\n",
    "\n",
    "    # Comprehensive MFCCs\n",
    "    comprehensive_mfccs = np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
    "\n",
    "    # Find spectral centroids\n",
    "    sc = librosa.feature.spectral_centroid(y=peak, sr=sample_rate)\n",
    "    \n",
    "    Audiodata_new['percentile_25'].append(per_25)\n",
    "    Audiodata_new['percentile_50'].append(per_50)\n",
    "    Audiodata_new['percentile_75'].append(per_75)\n",
    "    Audiodata_new['percentile_90'].append(per_90)\n",
    "    Audiodata_new['mfcc'].append(comprehensive_mfccs)\n",
    "    Audiodata_new['sc'].append(sc)\n",
    "\n",
    "df_new = pd.DataFrame.from_dict(Audiodata_new)\n",
    "\n",
    "# Both MFCCs and Percentiles\n",
    "mfcc_values = np.array(df_new['mfcc'].tolist())\n",
    "mfcc_values = mfcc_values.reshape(mfcc_values.shape[0], -1)\n",
    "\n",
    "sc_values = np.array(df_new['sc'].tolist())\n",
    "sc_values = sc_values.reshape(sc_values.shape[0], -1)\n",
    "\n",
    "percentile_values = df_new.iloc[:, :4].values\n",
    "\n",
    "new_data = np.concatenate((percentile_values, mfcc_values, sc_values), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
